Vamos. Te dejo el modelo de ejecuci√≥n cognitiva + el Policy Engine formal (en versi√≥n ‚Äúimplementable‚Äù para Skuldbot), con schemas, reglas y flujo de runtime.

1) Tres artefactos ‚Äúsource of truth‚Äù

En Skuldbot, todo gira alrededor de 3 contratos:
	1.	Node Manifest (por tipo de nodo/skill)
	2.	Workflow IR (tu flujo, independiente de UI)
	3.	Tenant Policy Pack (reglas por cliente/industria: HIPAA, SOC2, etc.)

‚∏ª

2) Node Manifest (contrato formal de cada nodo)

Esto es lo que te permite gobernar 205 nodos sin morir.

NodeManifest (ejemplo)

{
  "type": "data.tap.csv",
  "displayName": "Read CSV",
  "category": "Data Integration",
  "inputs": {
    "path": {"type":"string", "required": true},
    "hasHeader": {"type":"boolean", "required": false, "default": true}
  },
  "outputs": {
    "dataset": {"type":"dataset", "classification": "UNCLASSIFIED"}
  },

  "data": {
    "consumes": ["UNCLASSIFIED"],
    "produces": ["UNCLASSIFIED"],
    "propagation": "NONE"
  },

  "capabilities": {
    "egress": "NONE",
    "writes": "NONE",
    "deletes": "NONE",
    "privilegedAccess": false
  },

  "controls": {
    "requires": [],
    "supports": ["AUDIT_LOG", "ARTIFACT_ENCRYPTION"]
  },

  "runtime": {
    "idempotent": true,
    "retryable": true,
    "defaultRetry": {"max": 3, "backoffMs": 2000},
    "timeoutMs": 600000
  }
}

Manifiesto para nodos ‚Äúpeligrosos‚Äù (ej: Email / LLM externo)

{
  "type": "comm.email.send",
  "data": {
    "consumes": ["UNCLASSIFIED","PII","PHI"],
    "produces": ["UNCLASSIFIED"],
    "propagation": "NONE"
  },
  "capabilities": { "egress": "EXTERNAL", "writes": "EXTERNAL" },
  "controls": {
    "requires": ["DLP_SCAN", "HITL_APPROVAL_IF_PII_OR_PHI"],
    "supports": ["AUDIT_LOG","REDACTION"]
  }
}

3) Workflow IR (lo que el LLM genera y t√∫ compilas a React Flow)

Tu React Flow es vista; el IR es la verdad.

WorkflowIR (m√≠nimo robusto)

{
  "name": "Read Appointments",
  "version": "1.0.0",
  "variables": [
    {"key":"filePath","type":"string","classification":"UNCLASSIFIED"}
  ],
  "nodes": [
    {"id":"n1","type":"trigger.form","inputs":{}},
    {"id":"n2","type":"data.tap.csv","inputs":{"path":"{{vars.filePath}}"}},
    {"id":"n3","type":"dataquality.validate","inputs":{"dataset":"{{n2.outputs.dataset}}"}}
  ],
  "edges": [
    {"from":"n1","to":"n2"},
    {"from":"n2","to":"n3"}
  ]
}

4) Modelo de ejecuci√≥n cognitiva (Control Plane + Runner)

Tu ejecuci√≥n debe separar claramente planificaci√≥n de ejecuci√≥n.

4.1 Etapas del ‚ÄúCognitive Execution‚Äù
	1.	Plan (LLM ‚Üí IR)
	2.	Validate (schema + sem√°ntica + policy)
	3.	Compile (IR ‚Üí ExecutionPlan)
	4.	Enforce (policy gates + control injection)
	5.	Run (runner)
	6.	Observe (telemetr√≠a + evidence pack)
	7.	Learn (feedback ‚Üí recomendaciones)

ExecutionPlan (lo que corre el runner)

Incluye ya controles insertados y ‚Äúresolved references‚Äù.

{
  "runId": "run_123",
  "workflowVersion": "1.0.0",
  "steps": [
    {
      "stepId":"s1",
      "nodeId":"n2",
      "type":"data.tap.csv",
      "inputs":{"path":"/secure/input/a.csv","hasHeader":true},
      "controls":["AUDIT_LOG","ARTIFACT_ENCRYPTION"],
      "classification": {"in":"UNCLASSIFIED","out":"UNCLASSIFIED"},
      "retry":{"max":3,"backoffMs":2000},
      "timeoutMs":600000
    },
    {
      "stepId":"s2",
      "nodeId":"n3",
      "type":"dataquality.validate",
      "inputs":{"datasetRef":"artifact://s1/dataset"},
      "controls":["AUDIT_LOG"],
      "classification":{"in":"UNCLASSIFIED","out":"UNCLASSIFIED"}
    }
  ]
}

5) Policy Engine (formal) ‚Äî lo que te hace enterprise

El Policy Engine tiene 3 funciones:
	1.	Clasificaci√≥n y propagaci√≥n de PII/PHI a trav√©s del grafo
	2.	Gating (permitir / exigir controles / bloquear)
	3.	Auto-inserci√≥n de controles (masking, de-id, HITL, vault, DLP, etc.)

5.1 Taxonom√≠a de datos (simple pero suficiente)
	‚Ä¢	UNCLASSIFIED
	‚Ä¢	PII
	‚Ä¢	PHI
	‚Ä¢	PCI
	‚Ä¢	CREDENTIALS

Y una regla de ‚Äúdominancia‚Äù:
CREDENTIALS > PCI > PHI > PII > UNCLASSIFIED

5.2 Propagaci√≥n (regla base)

Para cada edge A‚ÜíB:
	‚Ä¢	inClass(B) = max(outClass(A), varClassUsedByB, constantsClass)
	‚Ä¢	outClass(B) depende de su manifest:
	‚Ä¢	si el nodo ‚Äúproduce PHI‚Äù (ej: parse EHR) => PHI
	‚Ä¢	si es ‚Äúredact‚Äù => baja clasificaci√≥n (PHI‚ÜíPII o PHI‚ÜíUNCLASSIFIED seg√∫n t√©cnica)
	‚Ä¢	si es ‚Äúpass-through‚Äù => out = in

Esto lo resuelves con un topological pass (DAG) o con iteraci√≥n hasta converger si permites ciclos (yo recomiendo bloquear ciclos o tratarlos como subflows con l√≠mites).

5.3 Policy Pack (por tenant / industria)

Ejemplo de TenantPolicyPack:


{
  "tenant": "UniversalGroup",
  "rules": [
    {
      "id": "HIPAA_NO_PHI_EGRESS",
      "when": {"dataContains":["PHI"], "capability":"egress", "egress":"EXTERNAL"},
      "then": {"action":"BLOCK", "reason":"PHI cannot be sent to external destinations"}
    },
    {
      "id": "PII_EMAIL_REQUIRES_HITL",
      "when": {"dataContains":["PII","PHI"], "nodeType":"comm.email.send"},
      "then": {"action":"REQUIRE_CONTROLS", "controls":["DLP_SCAN","HITL_APPROVAL"]}
    },
    {
      "id": "LLM_EXTERNAL_REDACTION_REQUIRED",
      "when": {"dataContains":["PII","PHI"], "nodeType":"ai.llm.call", "llmProvider":"external"},
      "then": {"action":"REQUIRE_CONTROLS", "controls":["REDACTION","PROMPT_GUARD"]}
    }
  ],
  "defaults": {
    "logging": {"redact": true, "storeDays": 90},
    "artifacts": {"encryptAtRest": true}
  }
}

6) Validaciones obligatorias (antes de ‚ÄúBuild‚Äù y antes de ‚ÄúRun‚Äù)

Divide validaci√≥n en 3 capas:

6.1 Schema validation (Ajv/Zod)
	‚Ä¢	estructura de IR correcta
	‚Ä¢	inputs requeridos

6.2 Semantic validation
	‚Ä¢	ids √∫nicos
	‚Ä¢	referencias {{nX.outputs.y}} existentes
	‚Ä¢	tipos compatibles (dataset ‚Üí validate)
	‚Ä¢	grafo v√°lido (no nodos hu√©rfanos, etc.)

6.3 Policy validation (lo importante)
	‚Ä¢	calcula data classification por nodo/edge
	‚Ä¢	eval√∫a reglas del policy pack
	‚Ä¢	genera:
	‚Ä¢	BLOCKS[] (no se puede compilar)
	‚Ä¢	REQUIRES_CONTROLS[] (auto insertables)
	‚Ä¢	WARNINGS[] (mejoras)

‚∏ª

7) Auto-inserci√≥n de controles (lo que te hace m√°gico)

Cuando el policy engine diga ‚ÄúREQUIRE_CONTROLS‚Äù, tienes 2 opciones:

Opci√≥n A: ‚Äúinvisible injection‚Äù (recomendado)

El usuario no ve nodos extra, pero el ExecutionPlan a√±ade wrappers:
	‚Ä¢	redact logs
	‚Ä¢	encrypt artifacts
	‚Ä¢	DLP scan
	‚Ä¢	HITL checkpoint

Opci√≥n B: ‚Äúvisible injection‚Äù

Inserta nodos en canvas:
	‚Ä¢	compliance.redact
	‚Ä¢	human.approval
	‚Ä¢	security.vault.store
	‚Ä¢	dlp.scan

Yo har√≠a ambas:
	‚Ä¢	invisible por defecto (experiencia limpia)
	‚Ä¢	bot√≥n ‚ÄúShow compliance controls‚Äù para verlo.

‚∏ª

8) Evidence Pack (para vender a regulated industries)

Por cada run, guardas:
	‚Ä¢	run.json (metadata)
	‚Ä¢	timeline.json (eventos step_start/step_end)
	‚Ä¢	inputs_redacted.json
	‚Ä¢	outputs_redacted.json
	‚Ä¢	artifacts/ (cifrados)
	‚Ä¢	policy_report.json (qu√© reglas aplicaron, qu√© controles se inyectaron)
	‚Ä¢	approvals.json (qui√©n aprob√≥ qu√©)

Eso te da audit ready de verdad.

‚∏ª

9) El ‚ÄúAI Planner‚Äù (para que el LLM no rompa compliance)

Tu planner debe recibir:
	‚Ä¢	Node Catalog (manifests resumidos)
	‚Ä¢	TenantPolicyPack (resumen)
	‚Ä¢	Objetivo del usuario
	‚Ä¢	Contexto (fuentes, destino, restricciones)

Y devolver solo IR.

Luego tu validator/policy engine:
	‚Ä¢	corrige (auto-fix loop 1‚Äì2)
	‚Ä¢	o bloquea con mensajes accionables.

‚∏ª

10) Qu√© har√≠a ma√±ana mismo en tu repo (orden de implementaci√≥n)
	1.	NodeManifest registry (JSON + loader)
	2.	IR schema + validator (Ajv)
	3.	Classification propagation (PHI/PII)
	4.	PolicyPack rules + evaluator (BLOCK/REQUIRE/WARN)
	5.	ExecutionPlan compiler (incluye controls)
	6.	Evidence pack writer (m√≠nimo viable)

Con eso ya tienes: ‚Äúcompliance-by-construction‚Äù.

‚∏ª

Si quieres que te lo deje a√∫n m√°s ‚Äúplug and play‚Äù, dime solo esto (una l√≠nea):
¬øTus nodos ya tienen un type estilo data.tap.csv / dataquality.validate como en la UI?
Si s√≠, te doy el JSON Schema exacto (Ajv) para NodeManifest, WorkflowIR, TenantPolicyPack y el pseudo-c√≥digo del propagator + evaluator tal cual para NestJS.

yo dije: Quiero que las variables se propaguen de nodo a nodo como hace n8n

Perfecto. ‚ÄúComo n8n‚Äù en realidad significa 3 cosas a la vez:
	1.	cada nodo recibe un contexto con outputs de nodos anteriores
	2.	puedes referenciar esos valores con expresiones (ej: {{$json.foo}})
	3.	el flujo puede operar por items (lista de registros) y cada nodo transforma esa lista

Te dejo un dise√±o Skuldbot-ready (y muy implementable) que replica ese patr√≥n sin volverte loco.

‚∏ª

1) Modelo de datos tipo n8n: items[] + json/binary

En n8n, casi todo viaja como una lista de items:

type Item = {
  json: Record<string, any>;          // datos estructurados
  binary?: Record<string, BinaryRef>; // archivos
  meta?: Record<string, any>;         // trazas, ids, etc.
}

type NodeIO = {
  items: Item[];
}

	‚Ä¢	Un CSV le√≠do produce items (cada fila = un item.json)
	‚Ä¢	Un PDF produce binary.file + json (campos extra√≠dos)
	‚Ä¢	Un ‚ÄúValidate Data‚Äù puede marcar meta.validationErrors

Clave: Si estandarizas esto, la propagaci√≥n ‚Äúsale sola‚Äù.

2) Contexto de ejecuci√≥n: ExecutionContext

Cada nodo corre con un contexto como:

type ExecutionContext = {
  vars: Record<string, any>;           // variables globales del workflow (inputs)
  env: Record<string, any>;            // env vars (no secrets)
  secrets: SecretRefStore;             // acceso controlado
  $run: { id: string; startedAt: string; tenantId: string };
  $node: Record<string, { items: Item[] }>; // outputs por nodoId o nombre
  $input: { items: Item[] };           // entrada del nodo actual
}

¬øQu√© se ‚Äúpropaga‚Äù?
	‚Ä¢	Por defecto: $input.items viene del nodo anterior (o merge si hay varios edges)
	‚Ä¢	Adem√°s: siempre est√° accesible ctx.$node.<nodeId>.items para referencias directas

Esto te permite:
	‚Ä¢	‚Äúp√°same lo que viene por el edge‚Äù ‚úÖ
	‚Ä¢	‚Äúaccede a outputs de cualquier nodo previo‚Äù ‚úÖ

‚∏ª

3) Lenguaje de expresiones (m√≠nimo viable)

Te recomiendo copiar el esp√≠ritu n8n sin copiar toda su complejidad:

Sintaxis (simple)
	‚Ä¢	{{ ... }} para expresiones
	‚Ä¢	Helpers:
	‚Ä¢	$json = ctx.$input.items[0].json (o item actual si est√°s en modo map)
	‚Ä¢	$item(i).json = item i
	‚Ä¢	$node("Read CSV").json = primer item del nodo (o .items)
	‚Ä¢	$vars.foo, $env.BAR
	‚Ä¢	len(), toNumber(), now(), coalesce()

Ejemplos:
	‚Ä¢	{{ $json.email }}
	‚Ä¢	{{ $node("Read CSV").items }}
	‚Ä¢	{{ coalesce($json.amount, 0) }}
	‚Ä¢	{{ $vars.filePath }}

Regla de oro: Si un input field contiene {{ }}, eval√∫as; si no, literal.

‚∏ª

4) Propagaci√≥n ‚Äúpor item‚Äù (modo n8n real)

Hay dos modos de ejecuci√≥n por nodo:

A) mode: "map" (default)

El nodo transforma item por item:
	‚Ä¢	input: items[]
	‚Ä¢	output: items[] (misma longitud o modificada)

Ej: ‚ÄúValidate Data‚Äù agrega meta.valid=true/false a cada item.

B) mode: "reduce" (aggregator)

Consume todos los items y produce 1 (o pocos):

Ej: ‚ÄúWrite CSV‚Äù, ‚ÄúSend Email summary‚Äù, ‚ÄúLoad to DB batch‚Äù.

Esto te permite: pipelines de datos y RPA en el mismo paradigma.

‚∏ª

5) Merge cuando un nodo tiene m√∫ltiples entradas

n8n tiene varias estrategias; t√∫ implementa 3 (suficiente):
	‚Ä¢	append: concatena items de todas las ramas
	‚Ä¢	zip: item1 con item1 (√∫til para joins simples)
	‚Ä¢	byKey: merge por llave (ej: customer_id)

En el IR:

{
  "id":"merge1",
  "type":"control.merge",
  "inputs": { "strategy":"append" }
}

6) Variables globales vs variables por flujo

Para ‚Äúvariables‚Äù tipo n8n, define 2 niveles:

Globales (workflow vars)
	‚Ä¢	definidas en trigger o settings
	‚Ä¢	disponibles como $vars

Temporales (por run)
	‚Ä¢	creadas por nodos ‚ÄúSet Variable‚Äù
	‚Ä¢	viven en ctx.vars pero con control (y audit)

Nodo:
	‚Ä¢	control.setVar { key: "threshold", value: "{{ $json.limit }}" }


7) C√≥mo lo haces robusto (y enterprise)

A) Tipado ligero + validaci√≥n

Cada input de nodo define su tipo (string/number/dataset/items/file).
Despu√©s de evaluar expresiones, validas.

B) Data classification se propaga con los items

Cada Item lleva meta.classification (UNCLASSIFIED/PII/PHI‚Ä¶).
Tu policy engine eval√∫a por:
	‚Ä¢	nodo capability + item.classification
	‚Ä¢	y si hay egress, exige controles

‚∏ª

8) En tu UI (React Flow) c√≥mo se siente ‚Äúcomo n8n‚Äù
	1.	Cada input field permite ‚ÄúExpression mode‚Äù (toggle)
	2.	Panel ‚ÄúData‚Äù muestra:
	‚Ä¢	$input preview (primeros 5 items)
	‚Ä¢	$node("X") preview
	‚Ä¢	$vars preview
	3.	Autocomplete en expresiones:
	‚Ä¢	$json.<keys>
	‚Ä¢	nodos previos y sus outputs

Eso hace que sea n8n vibes inmediatamente.

‚∏ª

9) Implementaci√≥n m√≠nima (lo que har√≠a primero)
	1.	Est√°ndar Item[] en todos los nodos
	2.	Resolver de expresiones {{ }} + helpers $json/$node/$vars
	3.	Ejecuci√≥n map y reduce
	4.	Merge append
	5.	Panel preview + autocomplete b√°sico

Con eso ya tienes propagaci√≥n de variables como n8n (y mejor, porque t√∫ tienes compliance nativo).

‚∏ª

Si me dices c√≥mo ejecutas hoy (uno de estos):
	‚Ä¢	A) cada nodo recibe un ‚Äúpayload object‚Äù suelto
	‚Ä¢	B) ya tienes algo tipo items[]/dataset

te adapto esto a tu realidad exacta y te dejo el contracto final de ExecutionContext + ejemplos de 3 nodos (Read CSV, Validate Data, LLM Call) con sus inputs/outputs y c√≥mo referenciarlos en expresiones.

yo dije: creo que ese modelo sera un poco pesado para mi porque tengo bases de datos

Te entiendo 100%. El modelo ‚Äúitems[]‚Äù tipo n8n funciona genial para eventos/JSON, pero cuando tu mundo es bases de datos + datasets grandes, puede volverse pesado si lo interpretas como ‚Äúpasar filas‚Äù por memoria.

La clave es esta:

üëâ propagar variables no significa propagar datos.
Significa propagar referencias (handles) a datos.

El enfoque correcto para Skuldbot (DB-first, liviano)

1) Contexto por referencia

En vez de items[] grandes, cada nodo produce ‚Äúsalidas‚Äù que son:
	‚Ä¢	valores peque√±os (string/number/json)
	‚Ä¢	DatasetRef (puntero a datos grandes)
	‚Ä¢	FileRef (puntero a archivo)
	‚Ä¢	TableRef / QueryRef (puntero a tabla o query)

Ejemplo:
	‚Ä¢	Read CSV ‚Üí datasetRef: ds_abc123
	‚Ä¢	DB Query ‚Üí datasetRef: ds_q987 (que internamente puede ser una vista/materializaci√≥n/consulta paginada)
	‚Ä¢	Validate Data ‚Üí reportRef: rpt_55, passed: true/false

Nada se copia. Solo viajan IDs.

‚∏ª

2) Tu ‚Äúpropagaci√≥n n8n‚Äù pero con handles

Sigues teniendo el feeling de n8n:
	‚Ä¢	inputs pueden usar expresiones {{ }}
	‚Ä¢	y acceder a outputs anteriores

Pero lo que fluye por los edges es un objeto liviano:

{
  "dataset": { "ref": "ds_abc123", "schema": "...", "rowCount": 12003450 },
  "meta": { "classification": "PHI" }
}

3) Dos modos de nodo (s√∫per simple)

Para DBs, esto te salva:

A) Nodes ‚Äúmetadata-only‚Äù (default)
Trabajan con DatasetRef y generan otros refs.
	‚Ä¢	filter, select columns, join, validate, profile‚Ä¶
	‚Ä¢	NO materializan salvo que sea necesario

B) Nodes ‚Äúmaterializers / sinks‚Äù
Escriben a destino:
	‚Ä¢	db.load, write.parquet, export.csv, send.email (con l√≠mites)

‚∏ª

Expresiones sin dolor (igual que n8n)

No necesitas $json ni items. Usa algo m√°s enterprise:
	‚Ä¢	{{ vars.filePath }}
	‚Ä¢	{{ node("Read CSV").outputs.dataset.ref }}
	‚Ä¢	{{ node("DB Query").outputs.dataset.rowCount }}

Y listo.

Tu runtime resuelve eso a valores/refs.

‚∏ª

C√≥mo modelar ‚Äúdataset‚Äù para que sea potente y barato

Define DatasetRef como una entidad en tu backend/orchestrator:

DatasetRef
	‚Ä¢	id
	‚Ä¢	sourceType: csv | db | api | parquet | view
	‚Ä¢	location: uri o (connId + query)
	‚Ä¢	schema
	‚Ä¢	classification: UNCLASSIFIED/PII/PHI
	‚Ä¢	lineage: de qu√© node sali√≥
	‚Ä¢	stats: rowCount, nullRates, etc. (lazy)

Ejemplos internos:
	‚Ä¢	CSV: file://.../a.csv
	‚Ä¢	DB: { connId:"pg1", query:"SELECT ...", params:{...} }
	‚Ä¢	Parquet: s3://bucket/path/*.parquet

As√≠ tus nodos de calidad/compliance trabajan sobre refs, no sobre datos en RAM.

‚∏ª

‚ÄúPropagaci√≥n de variables‚Äù como n8n, pero DB-friendly

Regla simple:
	‚Ä¢	El edge no pasa ‚Äúdata‚Äù, pasa ContextRef
	‚Ä¢	El contexto trae:
	‚Ä¢	outputs del nodo anterior (refs/valores)
	‚Ä¢	acceso a outputs de cualquier nodo por node(id)

Eso te da:
	‚Ä¢	chaining natural
	‚Ä¢	debugging f√°cil (porque todo tiene id)
	‚Ä¢	compliance f√°cil (porque classification viaja con el ref)

‚∏ª

Lo m√≠nimo que te recomiendo implementar ya
	1.	Output store por run:
	‚Ä¢	runId + nodeId -> outputs (refs/valores)
	2.	Expression resolver para {{ node("X").outputs... }}
	3.	DatasetRef registry (en DB del orchestrator)
	4.	Policy engine que eval√∫e usando classification del DatasetRef

Con eso tienes la experiencia ‚Äún8n‚Äù sin el peso de items[].

‚∏ª

Si me dices una cosa: tus nodos hoy, ¬ødevuelven dataset como (A) data en memoria, (B) path a archivo, o (C) query/tabla?
Con eso te propongo el contrato exacto de outputs (DatasetRef) que encaja con tu implementaci√≥n actual sin reescribir medio sistema.

Perfecto, Dubiel. Con lo que me pasaste ya puedo devolverte lo pedible: schemas Ajv exactos + pseudo-c√≥digo + ExecutionPlan. Te lo dejo en formato ‚Äúcopiar/pegar‚Äù (y con decisiones de dise√±o que encajan con tu category.action, container nodes y tus nodos compliance/dataquality).

‚∏ª

1) JSON Schema (Ajv) ‚Äî NodeManifest extendido (NodeTemplate+metadata)

Notas de dise√±o
	‚Ä¢	Lo llamo NodeManifest para separar ‚Äútemplate UI‚Äù vs ‚Äúcontrato runtime‚Äù.
	‚Ä¢	configSchema y outputSchema te los dejo como ‚Äúpassthrough‚Äù (porque ya tienes tu propio ConfigField/OutputField), pero con estructura m√≠nima para validar.
	‚Ä¢	Clasificaciones: UNCLASSIFIED | PII | PHI | PCI | CREDENTIALS.
	‚Ä¢	propagation define c√≥mo se calcula output classification:
	‚Ä¢	NONE = no hereda
	‚Ä¢	PASS_THROUGH = out = in (si no define produces expl√≠cito)
	‚Ä¢	DERIVE = nodo define produces seg√∫n l√≥gica (ej: extract PHI)
	‚Ä¢	TRANSFORM = puede bajar clasificaci√≥n si aplica control (mask/redact/tokenize)

node-manifest.schema.json

{
  "$id": "https://skuldbot.dev/schemas/node-manifest.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "SkuldBot NodeManifest",
  "type": "object",
  "required": ["type", "category", "label", "description", "icon", "defaultConfig", "configSchema", "data", "capabilities", "controls", "runtime"],
  "additionalProperties": false,

  "properties": {
    "type": {
      "type": "string",
      "minLength": 3,
      "pattern": "^[a-z]+\\.[a-z0-9_]+(\\.[a-z0-9_]+)*$",
      "description": "category.action[.subaction] e.g., trigger.form, ai.llm.call"
    },
    "category": {
      "type": "string",
      "minLength": 2,
      "pattern": "^[a-z][a-z0-9_]*$"
    },
    "label": { "type": "string", "minLength": 1 },
    "description": { "type": "string", "minLength": 1 },
    "icon": { "type": "string", "minLength": 1 },

    "defaultConfig": { "type": "object", "additionalProperties": true },

    "configSchema": {
      "type": "array",
      "minItems": 0,
      "items": { "$ref": "#/$defs/configField" }
    },
    "outputSchema": {
      "type": "array",
      "minItems": 0,
      "items": { "$ref": "#/$defs/outputField" }
    },

    "data": { "$ref": "#/$defs/dataPolicy" },
    "capabilities": { "$ref": "#/$defs/capabilities" },
    "controls": { "$ref": "#/$defs/controls" },
    "runtime": { "$ref": "#/$defs/runtime" }
  },

  "$defs": {
    "classification": {
      "type": "string",
      "enum": ["UNCLASSIFIED", "PII", "PHI", "PCI", "CREDENTIALS"]
    },

    "propagationMode": {
      "type": "string",
      "enum": ["NONE", "PASS_THROUGH", "DERIVE", "TRANSFORM"]
    },

    "dataPolicy": {
      "type": "object",
      "required": ["consumes", "produces", "propagation"],
      "additionalProperties": false,
      "properties": {
        "consumes": {
          "type": "array",
          "minItems": 1,
          "items": { "$ref": "#/$defs/classification" },
          "uniqueItems": true
        },
        "produces": {
          "type": "array",
          "minItems": 1,
          "items": { "$ref": "#/$defs/classification" },
          "uniqueItems": true
        },
        "propagation": { "$ref": "#/$defs/propagationMode" },

        "outputClassificationOverride": {
          "type": "object",
          "additionalProperties": { "$ref": "#/$defs/classification" },
          "description": "Optional per-output field classification override: { fieldName: 'PHI' }"
        }
      }
    },

    "egressMode": { "type": "string", "enum": ["NONE", "INTERNAL", "EXTERNAL"] },
    "writeMode": { "type": "string", "enum": ["NONE", "INTERNAL", "EXTERNAL"] },

    "capabilities": {
      "type": "object",
      "required": ["egress", "writes", "deletes", "privilegedAccess"],
      "additionalProperties": false,
      "properties": {
        "egress": { "$ref": "#/$defs/egressMode" },
        "writes": { "$ref": "#/$defs/writeMode" },
        "deletes": { "type": "boolean" },
        "privilegedAccess": { "type": "boolean" },

        "network": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "allowDomains": {
              "type": "array",
              "items": { "type": "string", "minLength": 1 },
              "uniqueItems": true
            },
            "denyDomains": {
              "type": "array",
              "items": { "type": "string", "minLength": 1 },
              "uniqueItems": true
            }
          }
        }
      }
    },

    "controlType": {
      "type": "string",
      "enum": [
        "AUDIT_LOG",
        "ARTIFACT_ENCRYPTION",
        "LOG_REDACTION",
        "DLP_SCAN",
        "HITL_APPROVAL",
        "MASK",
        "REDACT",
        "PSEUDONYMIZE",
        "HASH",
        "GENERALIZE",
        "ENCRYPT",
        "TOKENIZE",
        "VAULT_STORE",
        "PROMPT_GUARD",
        "RATE_LIMIT",
        "TIMEOUT_GUARD"
      ]
    },

    "controls": {
      "type": "object",
      "required": ["requires", "supports"],
      "additionalProperties": false,
      "properties": {
        "requires": {
          "type": "array",
          "items": { "$ref": "#/$defs/controlType" },
          "uniqueItems": true
        },
        "supports": {
          "type": "array",
          "items": { "$ref": "#/$defs/controlType" },
          "uniqueItems": true
        }
      }
    },

    "retryPolicy": {
      "type": "object",
      "required": ["max", "backoffMs"],
      "additionalProperties": false,
      "properties": {
        "max": { "type": "integer", "minimum": 0, "maximum": 50 },
        "backoffMs": { "type": "integer", "minimum": 0, "maximum": 3600000 }
      }
    },

    "runtime": {
      "type": "object",
      "required": ["idempotent", "retryable", "defaultRetry", "timeoutMs"],
      "additionalProperties": false,
      "properties": {
        "idempotent": { "type": "boolean" },
        "retryable": { "type": "boolean" },
        "defaultRetry": { "$ref": "#/$defs/retryPolicy" },
        "timeoutMs": { "type": "integer", "minimum": 1000, "maximum": 86400000 }
      }
    },

    "configField": {
      "type": "object",
      "required": ["key", "type"],
      "additionalProperties": true,
      "properties": {
        "key": { "type": "string", "minLength": 1 },
        "type": { "type": "string", "minLength": 1 },
        "required": { "type": "boolean" },
        "default": {}
      }
    },

    "outputField": {
      "type": "object",
      "required": ["key", "type"],
      "additionalProperties": true,
      "properties": {
        "key": { "type": "string", "minLength": 1 },
        "type": { "type": "string", "minLength": 1 },
        "classification": { "$ref": "#/$defs/classification" }
      }
    }
  }
}

2) JSON Schema (Ajv) ‚Äî TenantPolicyPack

Notas
	‚Ä¢	Reglas tipo ‚Äúwhen/then‚Äù.
	‚Ä¢	when soporta filtros por:
	‚Ä¢	dataContains (PII/PHI‚Ä¶)
	‚Ä¢	nodeType / nodeCategory
	‚Ä¢	capability flags (egress/writes/deletes/privilegedAccess)
	‚Ä¢	egress/writes mode
	‚Ä¢	then puede:
	‚Ä¢	BLOCK
	‚Ä¢	REQUIRE_CONTROLS
	‚Ä¢	WARN
	‚Ä¢	Puedes a√±adir severity y message.

tenant-policy-pack.schema.json

{
  "$id": "https://skuldbot.dev/schemas/tenant-policy-pack.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "SkuldBot TenantPolicyPack",
  "type": "object",
  "required": ["tenantId", "version", "rules", "defaults"],
  "additionalProperties": false,

  "properties": {
    "tenantId": { "type": "string", "minLength": 1 },
    "version": { "type": "string", "minLength": 1 },
    "industry": { "type": "string" },

    "defaults": {
      "type": "object",
      "required": ["logging", "artifacts"],
      "additionalProperties": false,
      "properties": {
        "logging": {
          "type": "object",
          "required": ["redact", "storeDays"],
          "additionalProperties": false,
          "properties": {
            "redact": { "type": "boolean" },
            "storeDays": { "type": "integer", "minimum": 1, "maximum": 3650 }
          }
        },
        "artifacts": {
          "type": "object",
          "required": ["encryptAtRest"],
          "additionalProperties": false,
          "properties": {
            "encryptAtRest": { "type": "boolean" }
          }
        }
      }
    },

    "rules": {
      "type": "array",
      "minItems": 1,
      "items": { "$ref": "#/$defs/rule" }
    }
  },

  "$defs": {
    "classification": {
      "type": "string",
      "enum": ["UNCLASSIFIED", "PII", "PHI", "PCI", "CREDENTIALS"]
    },
    "controlType": {
      "type": "string",
      "enum": [
        "AUDIT_LOG",
        "ARTIFACT_ENCRYPTION",
        "LOG_REDACTION",
        "DLP_SCAN",
        "HITL_APPROVAL",
        "MASK",
        "REDACT",
        "PSEUDONYMIZE",
        "HASH",
        "GENERALIZE",
        "ENCRYPT",
        "TOKENIZE",
        "VAULT_STORE",
        "PROMPT_GUARD",
        "RATE_LIMIT",
        "TIMEOUT_GUARD"
      ]
    },
    "actionType": { "type": "string", "enum": ["BLOCK", "REQUIRE_CONTROLS", "WARN"] },

    "when": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "dataContains": {
          "type": "array",
          "items": { "$ref": "#/$defs/classification" },
          "minItems": 1,
          "uniqueItems": true
        },
        "nodeType": { "type": "string", "minLength": 1 },
        "nodeCategory": { "type": "string", "minLength": 1 },

        "capability": { "type": "string", "enum": ["egress", "writes", "deletes", "privilegedAccess"] },
        "egress": { "type": "string", "enum": ["NONE", "INTERNAL", "EXTERNAL"] },
        "writes": { "type": "string", "enum": ["NONE", "INTERNAL", "EXTERNAL"] },
        "deletes": { "type": "boolean" },
        "privilegedAccess": { "type": "boolean" },

        "networkDomainMatches": { "type": "string", "minLength": 1 }
      }
    },

    "then": {
      "type": "object",
      "required": ["action"],
      "additionalProperties": false,
      "properties": {
        "action": { "$ref": "#/$defs/actionType" },
        "controls": {
          "type": "array",
          "items": { "$ref": "#/$defs/controlType" },
          "uniqueItems": true
        },
        "severity": { "type": "string", "enum": ["LOW", "MEDIUM", "HIGH", "CRITICAL"] },
        "message": { "type": "string" }
      },
      "allOf": [
        {
          "if": { "properties": { "action": { "const": "REQUIRE_CONTROLS" } }, "required": ["action"] },
          "then": { "required": ["controls"] }
        }
      ]
    },

    "rule": {
      "type": "object",
      "required": ["id", "when", "then"],
      "additionalProperties": false,
      "properties": {
        "id": { "type": "string", "minLength": 1 },
        "description": { "type": "string" },
        "when": { "$ref": "#/$defs/when" },
        "then": { "$ref": "#/$defs/then" }
      }
    }
  }
}

3) Pseudo-c√≥digo ‚Äî Classification Propagator

Principios
	‚Ä¢	Dominancia: CREDENTIALS > PCI > PHI > PII > UNCLASSIFIED
	‚Ä¢	Por nodo:
	‚Ä¢	inClass viene de inputs (edges + vars referenciadas + literals si aplican)
	‚Ä¢	outClass depende del manifest:
	‚Ä¢	DERIVE: usa max(manifest.produces)
	‚Ä¢	PASS_THROUGH: out = max(inClass, produces?) (si produces incluye algo m√°s alto)
	‚Ä¢	TRANSFORM: out = applyTransform(out, controlsInjected) (si hay mask/redact/tokenize)
	‚Ä¢	NONE: out = max(produces) (no hereda)
	‚Ä¢	Container nodes (control.if, try_catch, loop) se tratan como ‚Äúpass-through‚Äù para clasificaci√≥n del control plane (y propagas dentro recursivamente).

TypeScript-like pseudo

type Classification = "UNCLASSIFIED" | "PII" | "PHI" | "PCI" | "CREDENTIALS";

const rank: Record<Classification, number> = {
  UNCLASSIFIED: 0,
  PII: 1,
  PHI: 2,
  PCI: 3,
  CREDENTIALS: 4,
};

function maxClass(a: Classification, b: Classification): Classification {
  return rank[a] >= rank[b] ? a : b;
}

function maxOf(list: Classification[], fallback: Classification): Classification {
  let cur = fallback;
  for (const c of list) cur = maxClass(cur, c);
  return cur;
}

type NodeClassInfo = { in: Classification; out: Classification };

function propagateClassification(params: {
  dsl: BotDSL;
  manifestsByType: Record<string, NodeManifest>;
  varDefs?: Record<string, { classification?: Classification }>;
  // Optional: pre-injected controls by nodeId (if you do "evaluate then inject then propagate again")
  injectedControlsByNodeId?: Record<string, string[]>;
}): Record<string, NodeClassInfo> {

  const { dsl, manifestsByType } = params;
  const varDefs = params.varDefs ?? {};
  const injected = params.injectedControlsByNodeId ?? {};

  // 1) Build adjacency (edges) from your DSL representation
  // You likely have edges separately in your ReactFlow state; in BotDSL you can derive from node outputs wiring.
  // For now assume you can build: incoming[nodeId] = nodeIds that connect to it.
  const incoming: Record<string, string[]> = buildIncomingEdges(dsl);

  // 2) Topological order (assume DAG at the graph level; container nodes handled separately)
  const order = topoSort(dsl.nodes, incoming);

  const classMap: Record<string, NodeClassInfo> = {};

  // helper: compute classification from expressions like {{ vars.x }} or {{ node("n2").outputs... }}
  function inferFromConfig(node: DSLNode): Classification {
    // Minimal version: scan config values for variable references, pull their classification.
    // If you track DatasetRef classification at runtime, you can skip deep parsing here.
    let c: Classification = "UNCLASSIFIED";
    const refs = extractRefs(node.config); // implement: find "vars.xxx" used
    for (const ref of refs.vars) {
      const vc = varDefs[ref]?.classification ?? "UNCLASSIFIED";
      c = maxClass(c, vc);
    }
    return c;
  }

  function applyTransformIfAny(out: Classification, controls: string[], nodeType: string): Classification {
    // conservative: only allow downgrades if explicit transform controls exist
    // Example: TOKENIZE/REDACT can reduce PHI/PII to UNCLASSIFIED, depending on your policy.
    const hasRedact = controls.includes("REDACT");
    const hasTokenize = controls.includes("TOKENIZE");
    const hasMask = controls.includes("MASK") || controls.includes("PSEUDONYMIZE") || controls.includes("HASH") || controls.includes("GENERALIZE");

    // You can tune these:
    if (out === "PHI" && (hasRedact || hasTokenize)) return "UNCLASSIFIED";
    if (out === "PII" && (hasRedact || hasTokenize)) return "UNCLASSIFIED";
    if ((out === "PHI" || out === "PII") && hasMask) return out; // masking often still considered sensitive
    return out;
  }

  // 3) propagate
  for (const node of order) {
    const manifest = manifestsByType[node.type];
    if (!manifest) {
      // Unknown nodes: be safe
      classMap[node.id] = { in: "UNCLASSIFIED", out: "PHI" }; // or "PII" (your choice)
      continue;
    }

    // compute inbound classification
    let inC: Classification = "UNCLASSIFIED";

    // edges
    for (const parentId of (incoming[node.id] ?? [])) {
      const parentOut = classMap[parentId]?.out ?? "UNCLASSIFIED";
      inC = maxClass(inC, parentOut);
    }

    // variables referenced in config
    inC = maxClass(inC, inferFromConfig(node));

    // manifest consumes doesn't force classification up; it constrains allowed inputs.
    // You enforce consumes later in evaluator.

    // compute base out
    const producesMax = maxOf(manifest.data.produces, "UNCLASSIFIED");
    let outC: Classification;

    switch (manifest.data.propagation) {
      case "NONE":
        outC = producesMax;
        break;
      case "DERIVE":
        outC = producesMax; // treat as authoritative
        break;
      case "PASS_THROUGH":
        outC = maxClass(inC, producesMax);
        break;
      case "TRANSFORM":
        outC = maxClass(inC, producesMax);
        outC = applyTransformIfAny(outC, injected[node.id] ?? [], node.type);
        break;
      default:
        outC = maxClass(inC, producesMax);
    }

    classMap[node.id] = { in: inC, out: outC };

    // recurse into container children if present
    if (node.children?.length) {
      // You can run a sub-propagation using the container's inC as baseline for the first child.
      // Or you can just propagate within children based on their internal edges.
      // Keep it simple: treat container as pass-through for outer graph, propagate children internally.
      propagateChildren(node, manifest, classMap, manifestsByType, inC, injected);
    }
  }

  return classMap;
}

4) Pseudo-c√≥digo ‚Äî Policy Evaluator (gating + auto-controls)

Inputs
	‚Ä¢	dsl: BotDSL
	‚Ä¢	classMap: nodeId -> {in,out}
	‚Ä¢	manifestsByType
	‚Ä¢	policyPack: TenantPolicyPack

Output
	‚Ä¢	blocks[]
	‚Ä¢	requirements[] (nodeId -> controls[])
	‚Ä¢	warnings[]

Evaluator pseudo

type PolicyResult = {
  blocks: Array<{ nodeId: string; ruleId: string; message: string; severity: string }>;
  requiresControls: Record<string, Set<string>>;
  warnings: Array<{ nodeId: string; ruleId: string; message: string; severity: string }>;
};

function evaluatePolicies(params: {
  dsl: BotDSL;
  manifestsByType: Record<string, NodeManifest>;
  classMap: Record<string, { in: Classification; out: Classification }>;
  policyPack: TenantPolicyPack;
}): PolicyResult {

  const { dsl, manifestsByType, classMap, policyPack } = params;

  const res: PolicyResult = {
    blocks: [],
    requiresControls: {},
    warnings: [],
  };

  function addControl(nodeId: string, control: string) {
    if (!res.requiresControls[nodeId]) res.requiresControls[nodeId] = new Set<string>();
    res.requiresControls[nodeId].add(control);
  }

  // Apply global defaults (ex: always encrypt artifacts / redact logs)
  for (const node of dsl.nodes) {
    if (policyPack.defaults.artifacts.encryptAtRest) addControl(node.id, "ARTIFACT_ENCRYPTION");
    if (policyPack.defaults.logging.redact) addControl(node.id, "LOG_REDACTION");
    addControl(node.id, "AUDIT_LOG");
  }

  for (const node of dsl.nodes) {
    const manifest = manifestsByType[node.type];
    if (!manifest) continue;

    const nodeOut = classMap[node.id]?.out ?? "UNCLASSIFIED";
    const nodeCat = manifest.category;
    const caps = manifest.capabilities;

    // 1) hard constraints: manifest.controls.requires must be satisfied
    for (const c of manifest.controls.requires) addControl(node.id, c);

    // 2) enforce consumes: if input classification not allowed -> BLOCK
    const nodeIn = classMap[node.id]?.in ?? "UNCLASSIFIED";
    const consumesMaxAllowed = new Set(manifest.data.consumes);
    if (!consumesMaxAllowed.has(nodeIn) && rank[nodeIn] > maxAllowedRank(consumesMaxAllowed)) {
      res.blocks.push({
        nodeId: node.id,
        ruleId: "MANIFEST_CONSUMES_VIOLATION",
        message: `Node ${node.type} does not allow input classification ${nodeIn}`,
        severity: "HIGH",
      });
    }

    // 3) evaluate tenant rules
    for (const rule of policyPack.rules) {
      if (!matchesWhen(rule.when, { node, manifest, nodeOut })) continue;

      const action = rule.then.action;
      const msg = rule.then.message ?? rule.description ?? rule.id;
      const severity = rule.then.severity ?? "HIGH";

      if (action === "BLOCK") {
        res.blocks.push({ nodeId: node.id, ruleId: rule.id, message: msg, severity });
      } else if (action === "REQUIRE_CONTROLS") {
        for (const c of (rule.then.controls ?? [])) addControl(node.id, c);
      } else if (action === "WARN") {
        res.warnings.push({ nodeId: node.id, ruleId: rule.id, message: msg, severity });
      }
    }

    // 4) capability-based default gates (optional)
    // Example: if EXTERNAL egress and data is PII/PHI => require DLP + HITL
    if (caps.egress === "EXTERNAL" && (nodeOut === "PII" || nodeOut === "PHI")) {
      addControl(node.id, "DLP_SCAN");
      addControl(node.id, "HITL_APPROVAL");
    }
  }

  return res;
}

function matchesWhen(
  when: TenantPolicyPack["rules"][number]["when"],
  ctx: { node: DSLNode; manifest: NodeManifest; nodeOut: Classification }
): boolean {
  const { manifest, nodeOut } = ctx;

  if (when.dataContains?.length) {
    const ok = when.dataContains.some(c => rank[nodeOut] >= rank[c]); // contains-at-least
    if (!ok) return false;
  }
  if (when.nodeType && when.nodeType !== manifest.type) return false;
  if (when.nodeCategory && when.nodeCategory !== manifest.category) return false;

  if (when.egress && when.egress !== manifest.capabilities.egress) return false;
  if (when.writes && when.writes !== manifest.capabilities.writes) return false;
  if (typeof when.deletes === "boolean" && when.deletes !== manifest.capabilities.deletes) return false;
  if (typeof when.privilegedAccess === "boolean" && when.privilegedAccess !== manifest.capabilities.privilegedAccess) return false;

  // networkDomainMatches would require you to know the domain in config; optional

  return true;
}

function maxAllowedRank(consumes: Set<Classification>): number {
  let m = 0;
  for (const c of consumes) m = Math.max(m, rank[c]);
  return m;
}


5) ExecutionPlan ‚Äî estructura (lo que corre el runner con controles inyectados)

Dise√±o clave
	‚Ä¢	ExecutionPlan es linealizable para el runner: lista de steps con deps.
	‚Ä¢	Mant√©n nodeId + type + resolvedConfig.
	‚Ä¢	Incluye:
	‚Ä¢	controls[] (ya calculados)
	‚Ä¢	classification in/out
	‚Ä¢	retry/timeout (desde manifest + overrides)
	‚Ä¢	referencias a secrets sin exponerlos

execution-plan.schema.json (estructura recomendada)

{
  "$id": "https://skuldbot.dev/schemas/execution-plan.schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "SkuldBot ExecutionPlan",
  "type": "object",
  "required": ["planVersion", "run", "steps"],
  "additionalProperties": false,
  "properties": {
    "planVersion": { "type": "string", "minLength": 1 },
    "run": {
      "type": "object",
      "required": ["runId", "tenantId", "botId", "botVersion", "startedAt"],
      "additionalProperties": false,
      "properties": {
        "runId": { "type": "string", "minLength": 1 },
        "tenantId": { "type": "string", "minLength": 1 },
        "botId": { "type": "string", "minLength": 1 },
        "botVersion": { "type": "string", "minLength": 1 },
        "startedAt": { "type": "string", "format": "date-time" }
      }
    },
    "steps": {
      "type": "array",
      "minItems": 1,
      "items": { "$ref": "#/$defs/step" }
    }
  },
  "$defs": {
    "classification": { "type": "string", "enum": ["UNCLASSIFIED", "PII", "PHI", "PCI", "CREDENTIALS"] },
    "retryPolicy": {
      "type": "object",
      "required": ["max", "backoffMs"],
      "additionalProperties": false,
      "properties": {
        "max": { "type": "integer", "minimum": 0, "maximum": 50 },
        "backoffMs": { "type": "integer", "minimum": 0, "maximum": 3600000 }
      }
    },
    "step": {
      "type": "object",
      "required": ["stepId", "nodeId", "type", "deps", "resolvedConfig", "controls", "classification", "runtime"],
      "additionalProperties": false,
      "properties": {
        "stepId": { "type": "string", "minLength": 1 },
        "nodeId": { "type": "string", "minLength": 1 },
        "type": { "type": "string", "minLength": 3 },
        "deps": {
          "type": "array",
          "items": { "type": "string", "minLength": 1 },
          "uniqueItems": true
        },
        "resolvedConfig": { "type": "object", "additionalProperties": true },

        "controls": {
          "type": "array",
          "items": { "type": "string", "minLength": 1 },
          "uniqueItems": true
        },

        "classification": {
          "type": "object",
          "required": ["in", "out"],
          "additionalProperties": false,
          "properties": {
            "in": { "$ref": "#/$defs/classification" },
            "out": { "$ref": "#/$defs/classification" }
          }
        },

        "runtime": {
          "type": "object",
          "required": ["idempotent", "retry", "timeoutMs"],
          "additionalProperties": false,
          "properties": {
            "idempotent": { "type": "boolean" },
            "retry": { "$ref": "#/$defs/retryPolicy" },
            "timeoutMs": { "type": "integer", "minimum": 1000, "maximum": 86400000 }
          }
        },

        "outputs": {
          "type": "object",
          "additionalProperties": true,
          "description": "Populated at runtime by runner; optional in plan"
        }
      }
    }
  }
}

6) C√≥mo se conecta todo en tu pipeline (1:1 con tu DSL)

Build (Studio)
	1.	BotDSL ‚Üí valida schema b√°sico
	2.	propagateClassification(dsl, manifests, varDefs, injected?)
	3.	evaluatePolicies(dsl, manifests, classMap, tenantPolicyPack)
	4.	Si blocks.length > 0 ‚Üí no build
	5.	injectControls (invisible/visible)
	6.	Re-propagate (si transform puede bajar clasificaci√≥n)
	7.	compileExecutionPlan:
	‚Ä¢	topological order de nodos
	‚Ä¢	resolvedConfig (eval de expresiones + secrets refs)
	‚Ä¢	controls[] (set final)
	‚Ä¢	runtime from manifest

‚∏ª

Si quieres, te lo cierro con ‚ÄúcompileExecutionPlan‚Äù pseudo-c√≥digo

D√≠melo y te lo escribo tal cual (dep order + children nodes + try/catch + loop).

‚∏ª

√öltimo detalle (para que ma√±ana funcione)

T√∫ ahora tienes DSLNode.outputs: { success: string; error: string; }.
Eso sugiere que tus edges est√°n impl√≠citos por ‚Äúoutputs handles‚Äù.

‚úÖ Te recomiendo modelar edges expl√≠citos en el IR (aunque sea internamente) para:
	‚Ä¢	topo sort
	‚Ä¢	policy propagation
	‚Ä¢	evidence pack consistente

Pero no es obligatorio; lo puedes derivar.

‚∏ª

Si me confirmas una sola cosa:
	‚Ä¢	¬øTus container nodes (control.if, try_catch, loop) ya guardan sus conexiones como children[] + handles?
Te ajusto el topoSort + propagation para que respete scopes (muy importante para try/catch y loops).


Perfecto. Con eso ya puedo ajustar topoSort + propagation para tu DSL real (handles success/error/done, children[], scopes por container, loops sin ciclos infinitos, y try/catch heredando clasificaci√≥n).

Voy a darte:
	1.	Modelo de grafo ‚Äúexpandido‚Äù (para compilar y ordenar sin romper scopes)
	2.	TopoSort por bloques (containers como sub-DAGs con ‚Äúpuertos‚Äù)
	3.	Propagation con scopes (variables tipo ${item} solo dentro del loop)
	4.	Try/Catch (catch hereda clasificaci√≥n del try + error path)
	5.	Loops (propagaci√≥n por fixed-point acotado)

‚∏ª

1) Representaci√≥n interna recomendada: ‚ÄúBlock Graph‚Äù con puertos

Tu DSL ya tiene lo necesario. Internamente, compila a esto:
	‚Ä¢	Cada DSLNode es un block si tiene children[] (container)
	‚Ä¢	Cada block tiene ports (handles):
	‚Ä¢	success, error, y para containers done (y otros si existen)
	‚Ä¢	Dentro del block hay un subgrafo de children.

Funci√≥n clave

buildBlockIR(dslRoot) produce:

type Port = "success" | "error" | "done";

type NodeRef = { id: string }; // existing DSL id

type Edge = { from: string; port: Port; to: string | "END" };

type Block = {
  id: string;
  type: string;
  config: any;
  children: Array<Block | Leaf>;   // recursively
  edges: Edge[];                   // derived from outputs handles inside this scope
  ports: { success?: string|"END"; error?: string|"END"; done?: string|"END" };
}

type Leaf = {
  id: string;
  type: string;
  config: any;
  ports: { success?: string|"END"; error?: string|"END" };
}

Regla: outputs.success/error/done siempre referencian IDs del mismo scope (o END).
Si en UI permites salir del container a un nodo externo, entonces durante serializaci√≥n debes convertir eso en done del container, no en un child apuntando afuera.

2) TopoSort ‚Äúpor scope‚Äù (containers como subprogramas)

No intentes topological sort del grafo completo con loops/catch. Hazlo por niveles:

compileSteps(block, parentScope)

Devuelve una lista de steps (ExecutionPlan) en orden ejecutable, y metadatos de control (jump tables). En pocas palabras:
	‚Ä¢	Para nodos normales: steps lineales con deps
	‚Ä¢	Para containers: steps del container + steps de children + un ‚Äúcontrol step‚Äù que decide saltos

2.1 Orden dentro de un scope sin loops

Para un scope (lista de nodes) que sea DAG, topological sort normal.

Pero t√∫ tienes handles success/error, que en realidad forman un control-flow graph (CFG). CFG no siempre es DAG (por loops). Por eso:

‚úÖ Para execution plan, no necesitas topo sort estricto; necesitas orden de emisi√≥n + deps.

Orden recomendado:
	‚Ä¢	Recorrido desde el entry siguiendo success y metiendo error como ramas.
	‚Ä¢	Para nodos no visitados alcanzables, tambi√©n los emites.

Pseudo:

function emitOrderFromEntry(entryId, nodesById): string[] {
  const order: string[] = [];
  const seen = new Set<string>();
  const stack = [entryId];

  while (stack.length) {
    const id = stack.pop()!;
    if (id === "END" || seen.has(id)) continue;
    seen.add(id);
    order.push(id);

    const n = nodesById[id];
    // push error branch too so it's included
    if (n.outputs?.error) stack.push(n.outputs.error);
    if (n.outputs?.success) stack.push(n.outputs.success);
    // for containers, 'done' is continuation outside, handled at parent
  }
  return order;
}

Esto te da un orden estable para compilar steps y asignar deps (si los quieres).
Para el runner, t√∫ ejecutas siguiendo jump table, no por deps topol√≥gicos.

‚∏ª

3) Scopes de variables: stack de ‚ÄúScopeContext‚Äù

T√∫ quieres algo tipo ${item} v√°lido solo dentro de control.loop.

Hazlo as√≠:

type ScopeContext = {
  scopeId: string;                 // container id
  vars: Record<string, VarInfo>;   // vars visibles en este scope
};

type VarInfo = { classification?: Classification; type?: string };

type ScopeStack = ScopeContext[];

Reglas
	‚Ä¢	Siempre existe scope global con dsl.variables
	‚Ä¢	En control.loop, empujas un scope:
	‚Ä¢	define item (y/o index) como variables locales
	‚Ä¢	su classification inicial = classification del dataset/collection que est√°s iterando
	‚Ä¢	En control.try_catch, el try y el catch comparten el scope padre, pero el catch puede tener variables error locales.

Resolver de expresiones con scope

Tu extractor de refs debe recibir el stack y resolver:
	‚Ä¢	${item.foo} solo si item est√° en el scope stack
	‚Ä¢	vars.x siempre en global
	‚Ä¢	node("X").outputs... siempre (pero ojo: node X debe estar ejecutado antes en ese path; para compile-time basta con permitirlo y luego validar reachability si quieres)

‚∏ª

4) Classification propagation con containers y try/catch

4.1 Qu√© quieres lograr
	‚Ä¢	Propagar clasificaci√≥n ‚Äúa trav√©s‚Äù del control flow.
	‚Ä¢	catch hereda clasificaci√≥n del try (porque maneja fallos del mismo dato).
	‚Ä¢	Loops no deben colgarse: usar convergencia acotada.

4.2 Propagaci√≥n en CFG (no DAG)

En vez de topo pass, usa dataflow analysis (estilo compiladores):
	‚Ä¢	IN[n] = join(OUT[p]) para todos los predecesores p
	‚Ä¢	OUT[n] = transfer(n, IN[n])

Con join = max por rank.

Construcci√≥n de predecesores

Dentro de un scope:
	‚Ä¢	si A.success -> B, entonces A es pred de B
	‚Ä¢	si A.error -> C, entonces A es pred de C
	‚Ä¢	si control.try_catch:
	‚Ä¢	edge impl√≠cito: TRY block nodes on error ‚Üí CATCH entry
	‚Ä¢	si control.loop:
	‚Ä¢	edges del loop body pueden volver al entry del body (seg√∫n tu modelo); para propagaci√≥n, esto crea ciclo (ok)

Algoritmo: Worklist con l√≠mite

function propagateCFG(scopeNodes, scopeEdges, manifests, scopeStack): ClassMap {
  init IN/OUT a UNCLASSIFIED
  push all nodes into queue
  iter = 0
  while queue not empty and iter < MAX_ITERS:
     n = queue.pop()
     newIN = join(OUT[p] for p in preds[n]) + inferFromConfig(n, scopeStack)
     newOUT = transfer(n, newIN)
     if newOUT != OUT[n] or newIN != IN[n]:
        IN[n]=newIN; OUT[n]=newOUT
        push succs[n] into queue
     iter++
  return IN/OUT
}

MAX_ITERS: 5k o nodes*20 (suficiente).
En la pr√°ctica converge r√°pido por ser ‚Äúmax‚Äù monot√≥nico.


5) Transfer function por tipo de container

5.1 Nodos normales

Como ya te pas√©: out depende de manifest.propagation.

5.2 control.try_catch

Tr√°talo como un ‚Äúsupernodo‚Äù con 2 subscopes:
	‚Ä¢	TRY scope: childrenTry[]
	‚Ä¢	CATCH scope: childrenCatch[] (si lo separas) o children[] con marcador

Como tu DSL hoy tiene children[] sin distinguir, necesitas en config del try/catch:
	‚Ä¢	tryEntryId, catchEntryId (o un ‚Äúregion mapping‚Äù)
Si no lo tienes a√∫n, cr√©alo ya; si no, no puedes saber d√≥nde empieza catch.

Propagaci√≥n l√≥gica
	‚Ä¢	El IN[tryEntry] = IN[container]
	‚Ä¢	Corre propagateCFG en TRY
	‚Ä¢	Define tryOutMax = join de OUT de todos los exit nodes del TRY (los que van a done/success del container)
	‚Ä¢	Para CATCH:
	‚Ä¢	IN[catchEntry] = join( IN[container], tryOutMax )  ‚úÖ esto es ‚Äúcatch hereda‚Äù
	‚Ä¢	adem√°s, define variable local error como tryOutMax (o PHI si quieres conservador)
	‚Ä¢	Corre propagateCFG en CATCH
	‚Ä¢	OUT[container] = join( outTryDone, outCatchDone ) (lo que salga por done)

5.3 control.loop / control.while

No calcules ‚Äúout‚Äù por iteraci√≥n. Haz dataflow con ciclo:
	‚Ä¢	IN[bodyEntry] = join( IN[container], OUT[lastBodyExit] )
(lastBodyExit = nodes que vuelven al bodyEntry en cada iteraci√≥n)
	‚Ä¢	Al final:
	‚Ä¢	OUT[container] = OUT de los exit nodes del loop que van a done

Scope variables:
	‚Ä¢	item classification = classification del dataset/collection que alimenta el loop (si no lo sabes, usa IN[container]).

‚∏ª

6) Ajuste espec√≠fico para tu ‚Äúdone handle‚Äù

Para containers que tienen done, modela done como un puerto del container que se conecta a un nodo del scope padre.

En propagaci√≥n:
	‚Ä¢	OUT[container] se propaga al sucesor de done en el padre.
	‚Ä¢	Dentro del container, los nodes ‚Äúexit‚Äù son los que apuntan a END (del scope interno) o a un pseudo-target __DONE__.

Recomendaci√≥n: en compile interno, traduce done a un pseudo node __DONE__(containerId) para simplificar preds/succs.

‚∏ª

7) Pseudo-c√≥digo final: propagation respetando scopes (resumen)

function propagateAll(dsl: BotDSL, manifests, policyInjectedControls): NodeClassInfoMap {
  const globalScope = makeGlobalScope(dsl.variables);
  const result = new Map<string, {in:Cls; out:Cls}>();

  function propagateScope(nodes: DSLNode[], scopeStack: ScopeStack, entryId: string): { exitsOut: Cls } {
    const cfg = buildCFG(nodes);                 // includes success/error edges
    const { IN, OUT } = propagateCFG(cfg, manifests, scopeStack, policyInjectedControls);

    // store node results
    for (const id of cfg.nodeIds) result.set(id, { in: IN[id], out: OUT[id] });

    // exit classification: join of nodes that exit this scope (END or DONE)
    return { exitsOut: joinExits(cfg, OUT) };
  }

  function propagateNode(node: DSLNode, scopeStack: ScopeStack, inbound: Cls): Cls {
    if (!node.children?.length) {
      const out = transferLeaf(node, inbound, scopeStack);
      result.set(node.id, { in: inbound, out });
      return out;
    }

    // container
    if (node.type === "control.loop" || node.type === "control.while") {
      const loopScope = pushLoopScope(scopeStack, node, inbound); // defines item/index
      const entry = getContainerEntry(node); // from config
      const { exitsOut } = propagateScope(node.children, loopScope, entry);
      result.set(node.id, { in: inbound, out: exitsOut });
      return exitsOut;
    }

    if (node.type === "control.try_catch") {
      const { tryChildren, catchChildren, tryEntry, catchEntry } = splitTryCatch(node);
      const tryOut = propagateScope(tryChildren, scopeStack, tryEntry).exitsOut;

      const catchScope = pushCatchScope(scopeStack, tryOut); // defines error variable
      const catchOut = propagateScope(catchChildren, catchScope, catchEntry).exitsOut;

      const out = maxClass(tryOut, catchOut);
      result.set(node.id, { in: inbound, out });
      return out;
    }

    // control.if: propagate both branches, then join
    if (node.type === "control.if") {
      const { thenChildren, elseChildren, thenEntry, elseEntry } = splitIf(node);
      const thenOut = propagateScope(thenChildren, scopeStack, thenEntry).exitsOut;
      const elseOut = propagateScope(elseChildren, scopeStack, elseEntry).exitsOut;
      const out = maxClass(thenOut, elseOut);
      result.set(node.id, { in: inbound, out });
      return out;
    }

    // default container: treat as pass-through sub-scope
    const entry = getContainerEntry(node);
    const out = propagateScope(node.children, scopeStack, entry).exitsOut;
    result.set(node.id, { in: inbound, out });
    return out;
  }

  // Root propagation: build root CFG (top-level nodes)
  // Use dataflow CFG over top-level + treat containers as transfer nodes whose out depends on children (computed above).
  // Easiest: iterative solve at top level too: treat container OUT as unknown until children solved; repeat until convergence.
  propagateRootWithFixpoint(dsl.nodes, globalScope, propagateNode, result);

  return Object.fromEntries(result);
}

8) IMPORTANT: necesitas ‚ÄúentryId‚Äù por container

Para que esto sea s√≥lido, cada container debe tener (en config):
	‚Ä¢	entry: id del primer child o ‚Äústart‚Äù node interno
	‚Ä¢	para if/try:
	‚Ä¢	thenEntry, elseEntry
	‚Ä¢	tryEntry, catchEntry
Si hoy no lo tienes, a√±√°delo; es una mejora m√≠nima y te simplifica todo.

‚∏ª

Si quieres que lo deje cerrad√≠simo

Te puedo dar buildCFG() exacto para tu DSL con:
	‚Ä¢	puertos success/error/done
	‚Ä¢	pseudo nodes __DONE__, __END__
	‚Ä¢	separaci√≥n de regiones de try/catch e if

Pero para eso necesito saber c√≥mo distingues en children[] cu√°les pertenecen a then vs else y try vs catch.
Si ya lo tienes (aunque sea con config.regionMap o child.parentHandle), d√≠melo y te lo ajusto.

Me quedo con una tercera opci√≥n (mejor que A y B) y, si tienes que elegir entre A y B, te digo cu√°l.

La mejor propuesta: children con metadata de ‚Äúports‚Äù (scope-aware)

En vez de inventarte regionMap gen√©rico, modela lo que realmente est√°s construyendo en React Flow:
	‚Ä¢	el container tiene puertos internos (then, else, try, catch, body)
	‚Ä¢	cada hijo pertenece a un puerto (regi√≥n) y tiene un ‚Äúentry‚Äù

Opci√≥n C (recomendada): children como ‚Äúscoped children‚Äù


interface DSLNode {
  id: string;
  type: string;
  config: Record<string, any>;
  outputs: { success: string; error: string; done?: string };
  children?: DSLNode[];

  // NUEVO
  scope?: {
    ports: {
      [portName: string]: {
        nodeIds: string[];   // children IDs in this region
        entryId: string;     // first node in region
      }
    }
  }
}

Por qu√© es superior a A/B:
	‚Ä¢	te obliga a definir entryId (sin eso tu CFG siempre ser√° ambiguo)
	‚Ä¢	soporta nuevos containers en el futuro (switch, parallel, map/reduce) sin cambiar el modelo
	‚Ä¢	no duplicas estado (B tiende a duplicar y desincronizar)
	‚Ä¢	es f√°cil de construir desde React Flow: cada edge hacia el container con handle then/else/... define regi√≥n y entry

‚∏ª

Si tienes que escoger entre A vs B hoy

Prefiero B (region en cada child), pero con dos a√±adidos:
	1.	parentRegion en cada child
	2.	regionEntryId en el container (o detectarlo por edges)

Porque:
	‚Ä¢	regionMap (A) es fr√°gil: mantienes arrays de IDs que se desincronizan cuando mueves nodos, duplicas, borras, etc.
	‚Ä¢	Con B la regi√≥n ‚Äúvive‚Äù con el nodo, y el √°rbol se mantiene consistente.

B mejorado (m√≠nimo)

interface DSLNode {
  id: string;
  type: string;
  config: Record<string, any>;
  outputs: { success: string; error: string; done?: string };
  children?: DSLNode[];

  parentRegion?: "then" | "else" | "try" | "catch" | "body";
}

// En el container:
config: {
  regionEntry?: {
    then?: string;
    else?: string;
    try?: string;
    catch?: string;
    body?: string;
  }
}

C√≥mo cambia tu buildCFG() con Opci√≥n C (o B mejorado)

1) Construye CFG por scope/port

Para un container:
	‚Ä¢	separas children por regi√≥n usando scope.ports[port].nodeIds (o parentRegion)
	‚Ä¢	construyes un CFG para cada regi√≥n
	‚Ä¢	defines edges impl√≠citos:
	‚Ä¢	if: entrada eval ‚Üí then.entry / else.entry
	‚Ä¢	try_catch: try.entry; errores del try ‚Üí catch.entry
	‚Ä¢	loop: body.entry con back-edge controlado (para dataflow analysis)

2) Entry y Exits quedan claros

Cada regi√≥n tiene:
	‚Ä¢	entryId
	‚Ä¢	exitNodes (los que van a END / DONE internos)

Con eso:
	‚Ä¢	classification propagation converge
	‚Ä¢	compileExecutionPlan tiene jump table correcto
	‚Ä¢	evidence pack puede reportar ‚Äúbranch taken‚Äù

‚∏ª

Recomendaci√≥n pr√°ctica para tu estado actual (sin romper todo)

Como hoy else y catch viven fuera del container y dependen de error handle del container:

‚úÖ Puedes migrar en 2 fases:

Fase 1 (ya): a√±ade scope pero √∫salo opcionalmente
	‚Ä¢	control.if sigue como ‚Äúthen-only‚Äù
	‚Ä¢	control.try_catch sigue ‚Äútry-only‚Äù
	‚Ä¢	scope solo para loops (body) al principio

Fase 2: a√±ade regiones reales
	‚Ä¢	if con then/else
	‚Ä¢	try_catch con try/catch

Esto te permite evolucionar sin reescribir.

‚∏ª

Decisi√≥n final (para tu pregunta)
	‚Ä¢	Mejor opci√≥n: C (scope.ports con entryId)
	‚Ä¢	Si quieres elegir entre A y B: B (region por child) + entryIds en el container
	‚Ä¢	Evitar√≠a A salvo que tengas muy poco movimiento de nodos (porque se rompe f√°cil con drag/drop).

‚∏ª

Si quieres, te dejo el buildCFG() pseudo-c√≥digo exacto para:
	1.	tu modelo actual (then-only, try-only, loop body)
	2.	el modelo evolucionado con scope.ports

Dime cu√°l de los dos vas a implementar primero (actual + incremental, o te lanzas directo con regiones completas).

Perfecto. Te dejo el dise√±o completo ‚Äútipo compilador‚Äù para tu DSL con Opci√≥n C y soporte a todos esos containers. Voy a ser deliberadamente preciso para que lo implementes en NestJS/TS sin adivinar nada.

Abarco:
	1.	buildCFG() con pseudo-nodes __ENTRY__, __END__, __DONE__
	2.	topoSort() que respeta scopes (y no se rompe con loops)
	3.	propagateClassification() (dataflow worklist) con:
	‚Ä¢	try ‚Üí catch
	‚Ä¢	then/else independientes + join
	‚Ä¢	loop fixed-point
	‚Ä¢	parallel + switch

‚∏ª

0) Tipos base

type Port = string; // "success" | "error" | "done" | "then" | "else" | "try" | "catch" | "body" | "case_x" | "default" | "branch_0"...

type PseudoId = "__ENTRY__" | "__END__" | "__DONE__";

type Edge = { from: string; fromPort: Port; to: string; };

type CFG = {
  nodeIds: Set<string>;                      // includes real nodeIds + pseudo nodes per scope
  edges: Edge[];
  succ: Map<string, Set<string>>;
  pred: Map<string, Set<string>>;
  scopeOf: Map<string, string>;              // nodeId -> scopeId (containerId or "ROOT")
  containers: Map<string, DSLNode>;          // containerId -> node
  nodesById: Map<string, DSLNode>;           // real nodes only (not pseudo)
  entryId: string;                           // scope entry pseudo node id
  endId: string;                             // scope end pseudo node id
  doneId?: string;                           // if scope has done
};

Helper: pseudo IDs per scope

No uses un __ENTRY__ global; crea IDs por scope para no colisionar.

function ENTRY(scopeId: string) { return `__ENTRY__:${scopeId}`; }
function END(scopeId: string)   { return `__END__:${scopeId}`; }
function DONE(scopeId: string)  { return `__DONE__:${scopeId}`; }

1) buildCFG() completo (con scopes y puertos)

1.1 Reglas de conexi√≥n (lo m√°s importante)

Nodos leaf
	‚Ä¢	node.outputs.success -> target
	‚Ä¢	node.outputs.error -> target
Si el target es "END", conectas a END(scope).

Containers

Los containers tienen:
	‚Ä¢	scope.ports[portName].entryId (entry real dentro del container)
	‚Ä¢	y pueden tener outputs.done para continuar fuera.

Conexiones impl√≠citas por tipo:

control.if (then/else)
	‚Ä¢	__ENTRY__ -> ifNode (dentro del scope padre)
	‚Ä¢	ifNode decide:
	‚Ä¢	ifNode (then) -> entry(then)
	‚Ä¢	ifNode (else) -> entry(else)
	‚Ä¢	exits:
	‚Ä¢	cualquier leaf/container dentro de then/else que vaya a "END" del subscope, en realidad va a DONE(container) (o END(container) interno), y de ah√≠ a outputs.done del container (o success si usas esa sem√°ntica)

control.try_catch (try/catch)
	‚Ä¢	try_catchNode (try) -> entry(try)
	‚Ä¢	errores dentro del try:
	‚Ä¢	cualquier edge error que vaya a "END" del try-scope (o no est√© manejado) se redirige a entry(catch) (impl√≠cito)
	‚Ä¢	exits:
	‚Ä¢	try normal exit -> DONE(container)
	‚Ä¢	catch exit -> DONE(container)

control.loop y control.while (body)
	‚Ä¢	loopNode -> entry(body)
	‚Ä¢	exit normal del body -> back-edge a loopNode (siguiente iteraci√≥n) o a entry(body) (depende de tu runner)
	‚Ä¢	para CFG analysis, lo representamos como DONE(bodyScope) -> entry(bodyScope) (back-edge)
	‚Ä¢	salida del loop hacia afuera:
	‚Ä¢	loopNode.done -> targetOutside (o END del parent)

control.switch (case_x, default)
	‚Ä¢	switchNode -> entry(case_x) por cada case (impl√≠cito)
	‚Ä¢	switchNode -> entry(default) si existe
	‚Ä¢	exits de cualquier case/default -> DONE(container)

control.parallel (branch_0..n)
	‚Ä¢	parallelNode -> entry(branch_i) para cada branch
	‚Ä¢	exits de branch_i -> join en DONE(container) (es un join barrier)
	‚Ä¢	DONE(container) -> outputs.done afuera

‚∏ª

1.2 Construcci√≥n por scopes (recursivo)

Implementa un builder que construye CFG por scope y los ‚Äúembed‚Äù en el grafo global.

buildCFG(dslRootNodes)

function buildCFG(rootNodes: DSLNode[]): CFG {
  const nodesById = new Map<string, DSLNode>();
  const containers = new Map<string, DSLNode>();
  indexNodes(rootNodes, nodesById, containers);

  const scopeOf = new Map<string, string>();
  const edges: Edge[] = [];

  // Build ROOT scope pseudo nodes
  const rootScopeId = "ROOT";
  const rootEntry = ENTRY(rootScopeId);
  const rootEnd = END(rootScopeId);

  // add pseudo nodes
  const nodeIds = new Set<string>([rootEntry, rootEnd]);

  // attach scope info
  scopeOf.set(rootEntry, rootScopeId);
  scopeOf.set(rootEnd, rootScopeId);

  // Assign scopeOf for real nodes (root level initially)
  for (const n of rootNodes) assignScope(n, rootScopeId, scopeOf);

  // Add edges for ROOT entry to first nodes (if you have triggers, pick entry nodes from triggers list)
  // Here assume you have an implicit "entry" list; else take all triggers or all roots with no predecessors.
  const entryNodes = pickRootEntryNodes(rootNodes); // you define
  for (const id of entryNodes) edges.push({ from: rootEntry, fromPort: "success", to: id });

  // Build edges within ROOT scope (handles success/error/done)
  buildScopeEdges(rootScopeId, rootNodes, edges, scopeOf, nodesById);

  // Now recurse: for each container in ROOT, build its internal scope CFG and connect via implicit region edges.
  for (const n of rootNodes) {
    if (n.children?.length) buildContainerScopes(n, edges, scopeOf, nodesById, nodeIds);
    nodeIds.add(n.id);
  }

  // Finally compute succ/pred maps
  const { succ, pred } = computeAdjacency(edges);

  // Ensure nodeIds contains all ids appearing in edges
  for (const e of edges) { nodeIds.add(e.from); nodeIds.add(e.to); }

  return {
    nodeIds,
    edges,
    succ,
    pred,
    scopeOf,
    containers,
    nodesById,
    entryId: rootEntry,
    endId: rootEnd
  };
}

Index and scope assignment

function indexNodes(nodes: DSLNode[], nodesById: Map<string, DSLNode>, containers: Map<string, DSLNode>) {
  for (const n of nodes) {
    nodesById.set(n.id, n);
    if (n.children?.length) containers.set(n.id, n);
    if (n.children?.length) indexNodes(n.children, nodesById, containers);
  }
}

function assignScope(node: DSLNode, scopeId: string, scopeOf: Map<string,string>) {
  scopeOf.set(node.id, scopeId);
  if (node.children?.length) {
    // children belong to this container scope (containerId)
    for (const ch of node.children) assignScope(ch, node.id, scopeOf);
  }
}

Build edges for a flat list in a scope

This uses outputs.success/error/done. "END" maps to END(scopeId).

function buildScopeEdges(scopeId: string, nodes: DSLNode[], edges: Edge[], scopeOf: Map<string,string>, nodesById: Map<string,DSLNode>) {
  const endId = END(scopeId);
  // ensure pseudo nodes exist via later nodeIds fill; ok
  for (const n of nodes) {
    // success
    if (n.outputs?.success) {
      edges.push({
        from: n.id,
        fromPort: "success",
        to: n.outputs.success === "END" ? endId : n.outputs.success
      });
    }
    // error
    if (n.outputs?.error) {
      edges.push({
        from: n.id,
        fromPort: "error",
        to: n.outputs.error === "END" ? endId : n.outputs.error
      });
    }
    // done (only containers typically)
    if (n.outputs?.done) {
      edges.push({
        from: n.id,
        fromPort: "done",
        to: n.outputs.done === "END" ? endId : n.outputs.done
      });
    }
  }
}

Build container scopes and implicit region edges

This is the core.

function buildContainerScopes(
  container: DSLNode,
  edges: Edge[],
  scopeOf: Map<string,string>,
  nodesById: Map<string,DSLNode>,
  nodeIds: Set<string>
) {
  const cId = container.id;

  // create pseudo nodes for container scope
  const cEntry = ENTRY(cId);
  const cEnd   = END(cId);
  const cDone  = DONE(cId);

  nodeIds.add(cEntry); nodeIds.add(cEnd); nodeIds.add(cDone);
  scopeOf.set(cEntry, cId); scopeOf.set(cEnd, cId); scopeOf.set(cDone, cId);

  // connect container node to its internal entry pseudo (optional but useful for analysis)
  edges.push({ from: container.id, fromPort: "enter", to: cEntry });

  // build internal edges among children based on their outputs
  buildScopeEdges(cId, container.children ?? [], edges, scopeOf, nodesById);

  // map any "END" inside this container scope to cDone (NOT cEnd) because exiting region means "container completed"
  // Easiest: after edges are built, rewrite edges whose `to` is END(cId) into cDone.
  rewriteScopeEndToDone(cId, edges);

  // Now, implicit edges between container and region entries
  const ports = container.scope?.ports ?? {};
  function portEntry(portName: string): string | null {
    const p = ports[portName];
    if (!p) return null;
    return p.entryId || null;
  }

  switch (container.type) {
    case "control.if": {
      const thenEntry = portEntry("then");
      const elseEntry = portEntry("else");
      if (thenEntry) edges.push({ from: container.id, fromPort: "then", to: thenEntry });
      if (elseEntry) edges.push({ from: container.id, fromPort: "else", to: elseEntry });
      // When container completes, flow continues via outputs.done or outputs.success (you choose; you said containers have done)
      edges.push({ from: cDone, fromPort: "done", to: container.outputs.done ?? container.outputs.success ?? END(scopeOf.get(container.id)!) });
      break;
    }

    case "control.try_catch": {
      const tryEntry = portEntry("try");
      const catchEntry = portEntry("catch");
      if (tryEntry) edges.push({ from: container.id, fromPort: "try", to: tryEntry });
      // redirect any unhandled error in try-scope to catchEntry
      if (catchEntry) {
        redirectTryErrorsToCatch(container, catchEntry, edges, scopeOf);
        edges.push({ from: container.id, fromPort: "catch", to: catchEntry }); // optional for analysis
      }
      edges.push({ from: cDone, fromPort: "done", to: container.outputs.done ?? container.outputs.success ?? END(scopeOf.get(container.id)!) });
      break;
    }

    case "control.loop":
    case "control.while": {
      const bodyEntry = portEntry("body");
      if (bodyEntry) edges.push({ from: container.id, fromPort: "body", to: bodyEntry });
      // loop back-edge: when body scope exits -> back to bodyEntry (next iteration)
      if (bodyEntry) edges.push({ from: cDone, fromPort: "iterate", to: bodyEntry });
      // and also allow loop to finish via container.outputs.done (your runner decides exit condition)
      edges.push({ from: container.id, fromPort: "done", to: container.outputs.done ?? END(scopeOf.get(container.id)!) });
      break;
    }

    case "control.switch": {
      for (const k of Object.keys(ports)) {
        if (k.startsWith("case_") || k === "default") {
          const e = portEntry(k);
          if (e) edges.push({ from: container.id, fromPort: k, to: e });
        }
      }
      edges.push({ from: cDone, fromPort: "done", to: container.outputs.done ?? container.outputs.success ?? END(scopeOf.get(container.id)!) });
      break;
    }

    case "control.parallel": {
      for (const k of Object.keys(ports)) {
        if (k.startsWith("branch_")) {
          const e = portEntry(k);
          if (e) edges.push({ from: container.id, fromPort: k, to: e });
        }
      }
      // join barrier: branches exit -> cDone (already via rewrite of END->DONE)
      edges.push({ from: cDone, fromPort: "done", to: container.outputs.done ?? container.outputs.success ?? END(scopeOf.get(container.id)!) });
      break;
    }

    default: {
      // generic container: treat as body
      const bodyEntry = portEntry("body");
      if (bodyEntry) edges.push({ from: container.id, fromPort: "body", to: bodyEntry });
      edges.push({ from: cDone, fromPort: "done", to: container.outputs.done ?? container.outputs.success ?? END(scopeOf.get(container.id)!) });
    }
  }

  // recurse into nested containers
  for (const ch of (container.children ?? [])) {
    nodeIds.add(ch.id);
    if (ch.children?.length) buildContainerScopes(ch, edges, scopeOf, nodesById, nodeIds);
  }
}

function rewriteScopeEndToDone(scopeId: string, edges: Edge[]) {
  const end = END(scopeId);
  const done = DONE(scopeId);
  for (const e of edges) {
    if (e.to === end) e.to = done;
  }
}

Redirect try errors to catch

This is what makes ‚Äútry propagates to catch‚Äù correct.

function redirectTryErrorsToCatch(container: DSLNode, catchEntry: string, edges: Edge[], scopeOf: Map<string,string>) {
  // In your model, nodes inside TRY region will have error edges.
  // We want: if an error edge goes to DONE(scope) (meaning "unhandled") -> send to catchEntry.
  // That assumes try-scope exits were rewritten to DONE(containerId). For region-level try/catch you likely want done per region,
  // but simplest: treat all child nodes in try region as belonging to container scope and use an explicit region scoping.
  // With Opci√≥n C, you can identify try nodeIds list and only rewrite those.

  const tryIds = new Set(container.scope?.ports?.["try"]?.nodeIds ?? []);
  const cDone = DONE(container.id);

  for (const e of edges) {
    if (e.fromPort !== "error") continue;
    if (!tryIds.has(e.from)) continue;
    // if error goes to container done (meaning unhandled within try), redirect to catch entry
    if (e.to === cDone) {
      e.to = catchEntry;
    }
  }
}

Nota importante: Para try/catch real y limpio, conviene que cada regi√≥n tenga su propio END/DONE (ej: __DONE__:container:try).
Pero con tu estructura actual (un solo children[]), lo anterior funciona si usas scope.ports.try.nodeIds como filtro.

2) topoSort() ‚Äúque respete scopes‚Äù

En control-flow (con loops), el topoSort ‚Äúpuro‚Äù no existe (ciclos). Lo que necesitas es:
	‚Ä¢	SCC condensation DAG (Kahn sobre componentes) para:
	‚Ä¢	orden de an√°lisis
	‚Ä¢	orden de compilaci√≥n
	‚Ä¢	dentro de un SCC (loop), usas el worklist de dataflow.

topoSortScopes(cfg)
	‚Ä¢	Construye SCCs (Tarjan / Kosaraju)
	‚Ä¢	Contrae SCCs a super-nodos
	‚Ä¢	Kahn sobre DAG resultante

Pseudo:

function topoSort(cfg: CFG): string[] {
  const sccs = tarjanSCC(cfg.succ, cfg.nodeIds);
  const { dagSucc, indeg } = buildCondensationDag(sccs, cfg.succ);

  const q: string[] = [];
  for (const compId of dagSucc.keys()) if ((indeg.get(compId) ?? 0) === 0) q.push(compId);

  const compOrder: string[] = [];
  while (q.length) {
    const c = q.shift()!;
    compOrder.push(c);
    for (const nx of (dagSucc.get(c) ?? [])) {
      indeg.set(nx, (indeg.get(nx) ?? 0) - 1);
      if ((indeg.get(nx) ?? 0) === 0) q.push(nx);
    }
  }

  // Expand comps into node order: stable within SCC by DFS from entry (optional)
  const order: string[] = [];
  for (const compId of compOrder) {
    const nodes = sccs.get(compId)!;
    for (const id of stableOrderWithinComp(nodes, cfg)) order.push(id);
  }
  return order;
}

Con esto respetas scopes porque scopeOf te permite excluir pseudo nodes o analizarlos primero, y containers quedan dentro del mismo SCC si hay back-edge.

3) propagateClassification() con regiones y containers

Aqu√≠ s√≠ se aplica dataflow.

3.1 Principio

Haces un IN/OUT por nodo real y por pseudo nodes (ENTRY/DONE) si quieres; yo recomiendo:
	‚Ä¢	ENTRY(scope) tiene IN = del predecessor outside
	‚Ä¢	DONE(scope) out = join de exits del scope

Join operator

join = maxClass

Transfer operator

OUT[node] = transfer(node, IN[node]) (seg√∫n NodeManifest + controles)

‚∏ª

3.2 Dataflow worklist general

Funciona incluso con loops y parallel.

function propagateClassification(cfg: CFG, manifests: Record<string, NodeManifest>, injectedControls: Record<string,string[]>): Record<string,{in:Cls; out:Cls}> {
  const IN: Record<string,Cls> = {};
  const OUT: Record<string,Cls> = {};

  for (const id of cfg.nodeIds) { IN[id] = "UNCLASSIFIED"; OUT[id] = "UNCLASSIFIED"; }

  const q: string[] = Array.from(cfg.nodeIds); // init all
  const MAX = cfg.nodeIds.size * 30;

  let iter = 0;
  while (q.length && iter < MAX) {
    iter++;
    const n = q.shift()!;
    const preds = cfg.pred.get(n) ?? new Set<string>();

    // compute new IN
    let newIn: Cls = "UNCLASSIFIED";
    for (const p of preds) newIn = maxClass(newIn, OUT[p]);

    // (optional) add inferFromConfig refs based on current scope vars
    newIn = maxClass(newIn, inferFromConfigWithScopes(n, cfg, manifests));

    // transfer
    const newOut = transfer(n, newIn, cfg, manifests, injectedControls);

    const changed = (newIn !== IN[n]) || (newOut !== OUT[n]);
    IN[n] = newIn;
    OUT[n] = newOut;

    if (changed) {
      for (const s of (cfg.succ.get(n) ?? new Set<string>())) q.push(s);
    }
  }

  // return only real nodes (exclude pseudo if you want)
  const res: Record<string,{in:Cls; out:Cls}> = {};
  for (const [id, node] of cfg.nodesById.entries()) res[id] = { in: IN[id], out: OUT[id] };
  return res;
}

3.3 Transfer() que maneje containers (key)

Para leaf node: as you already had.

Para container nodes: su OUT debe ser el OUT del DONE(containerId) (porque done ya es join de exits de sus regiones). Como ya construimos rewrite END->DONE, eso ocurre autom√°ticamente: DONE(containerId) recibir√° preds desde todos los exits del container.

Entonces:

function transfer(id: string, inC: Cls, cfg: CFG, manifests, injected): Cls {
  // pseudo nodes: by default pass-through
  if (id.startsWith("__ENTRY__") || id.startsWith("__DONE__") || id.startsWith("__END__")) return inC;

  const node = cfg.nodesById.get(id);
  if (!node) return inC;

  // container node: treat as pass-through; its real effect comes from its internal CFG and DONE barrier
  if (node.children?.length) {
    // out from container is max(inC, OUT[DONE(containerId)]) ??? Actually OUT[DONE] already depends on internal exits.
    // But to avoid circularity, keep container node transfer as inC, and rely on edges from __DONE__ to outside.
    // In our buildCFG, outside continuation is from __DONE__ -> next, NOT from container.id -> next (except explicit done handle on container).
    return inC;
  }

  // leaf: use manifest rules
  const manifest = manifests[node.type];
  const produces = maxOf(manifest.data.produces, "UNCLASSIFIED");

  let out = inC;
  switch (manifest.data.propagation) {
    case "NONE": out = produces; break;
    case "DERIVE": out = produces; break;
    case "PASS_THROUGH": out = maxClass(inC, produces); break;
    case "TRANSFORM":
      out = maxClass(inC, produces);
      out = applyTransform(out, injected[id] ?? []);
      break;
    default:
      out = maxClass(inC, produces);
  }
  return out;
}

Importante: ‚Äútry propaga a catch‚Äù

Eso ya est√° modelado por redirectTryErrorsToCatch(): errores desde try region se convierten en edges al catchEntry.
Entonces el worklist propagar√° OUT(try nodes) ‚Üí IN(catchEntry) autom√°ticamente.

then/else independientes

Como ifNode.then -> thenEntry y ifNode.else -> elseEntry, cada rama tendr√° su dataflow.
Los exits de ambas ramas van a __DONE__:ifNode (join barrier).
Luego __DONE__ propaga al done outside.

loop body propaga al siguiente ciclo

Como agregamos __DONE__:loop -> bodyEntry, hay ciclo; dataflow converge por monotonic max.

parallel branches

Como los branches salen a __DONE__:parallel (join barrier), __DONE__ ser√° join de outs de branches.

switch cases

Todos los case entries conectados desde switchNode. Exits join in done.

‚∏ª

4) Edges impl√≠citos ‚Äúeval ‚Üí regions‚Äù

En tu CFG, esto ya lo modelamos como edges desde container.id con fromPort then/else/try/... a los entryId de cada regi√≥n.

Consejo pr√°ctico: agrega un nodo pseudo __EVAL__:containerId si quieres diferenciar la evaluaci√≥n de condici√≥n del container. No es requerido, pero ayuda para evidence pack (‚Äúwhich branch selected‚Äù).

‚∏ª

5) Un detalle cr√≠tico: ‚Äúfuentes de error‚Äù

En try_catch, hay dos fuentes:
	‚Ä¢	error handle de cada nodo dentro de try
	‚Ä¢	excepciones runtime no representadas (timeouts, thrown)
Tu runner debe normalizar todo a ‚Äúerror edge‚Äù del step. En CFG, asume que todo node tiene error.

Tu policy propagation ser√° conservadora (bien).

‚∏ª

6) Scope variables dentro de loop (tu requirement)

En inferFromConfigWithScopes, cuando est√°s dentro del control.loop.body port, expone ${item}.

C√≥mo saber que un node est√° en ‚Äúbody‚Äù:
	‚Ä¢	con Opci√≥n C, container.scope.ports.body.nodeIds te lo dice.
	‚Ä¢	mant√©n un regionOfNode: Map<childId, {containerId, portName}> durante buildCFG.

Entonces:
	‚Ä¢	si regionOfNode.get(nodeId)?.portName === "body" y container.type in (loop/while) ‚Üí define item en scope resolver.

Esto solo afecta inferFromConfig (para clasificar inputs por refs) y tu runtime resolver (para evaluar expresiones).

‚∏ª

7) Checklist de implementaci√≥n (para que salga en 1 sprint)
	1.	Implementar scope.ports en DSL serializaci√≥n (desde ReactFlow handles)
	2.	Implementar buildCFG() como arriba (con rewrite END->DONE)
	3.	Implementar SCC-based topoSort (para an√°lisis/compilaci√≥n)
	4.	Implementar worklist propagation (monotonic)
	5.	A√±adir regionOfNode para scopes (loop item)
	6.	Ajustar policy evaluator para usar OUT por node y for external egress require controls

‚∏ª

Pregunta m√≠nima (para cerrar exacto)

En control.loop / control.while:
¬øel done se toma desde el container node (cuando condici√≥n falla) o desde el body (un break node)?
	‚Ä¢	Si es ‚Äúcondici√≥n falla‚Äù: perfecto como lo model√© (container has done out).
	‚Ä¢	Si hay ‚Äúbreak‚Äù: a√±ade un node control.break que haga success -> __DONE__:loop.

D√≠melo y te ajusto el edge model con break/continue (super √∫til para no forzar ciclos en todos los casos).

Perfecto. Con eso cierro el modelo de edges para break/continue sin romper tu estado actual (done desde el container). Te dejo el ajuste completo, incluyendo los nuevos pseudo-nodes y c√≥mo buildCFG() debe reescribir conexiones.

1) Nuevos pseudo-nodes por loop/while

Para cada container control.loop / control.while crea adem√°s de:
	‚Ä¢	__ENTRY__:loopId
	‚Ä¢	__DONE__:loopId
	‚Ä¢	__END__:loopId (si lo usas internamente)

agrega:
	‚Ä¢	__NEXT_ITER__:loopId  ‚úÖ (punto de ‚Äúsiguiente iteraci√≥n‚Äù)

Helpers:

function NEXT(scopeId: string) { return `__NEXT_ITER__:${scopeId}`; }

2) Sem√°ntica clara (runtime + CFG)

Estado actual (se mantiene)
	‚Ä¢	El container node decide terminar el loop cuando condici√≥n falla / items se agotan:
	‚Ä¢	loopNode.done -> nextOutside

Nuevo: control.break
	‚Ä¢	Dentro del body, al ejecutarse:
	‚Ä¢	sale del loop inmediatamente ‚Üí va a __DONE__:<loopId> (join/exit del loop)

Nuevo: control.continue
	‚Ä¢	Dentro del body, al ejecutarse:
	‚Ä¢	salta a siguiente iteraci√≥n ‚Üí va a __NEXT_ITER__:<loopId>
	‚Ä¢	__NEXT_ITER__:<loopId> debe reconectar al bodyEntry del loop (inicio de iteraci√≥n)

‚∏ª

3) Puertos/edges impl√≠citos para loop (actualizado)

Para control.loop/control.while:
	1.	Entrada al body

	‚Ä¢	loopNode (body) -> bodyEntry

	2.	Salida normal del body

	‚Ä¢	Cualquier ‚ÄúEND‚Äù interno del body (lo que hoy reescribes) va a __NEXT_ITER__:<loopId>
(antes lo mand√°bamos a __DONE__ y luego back-edge; ahora lo hacemos m√°s sem√°ntico)

	3.	continue

	‚Ä¢	control.continue.success -> __NEXT_ITER__:<loopId>

	4.	break

	‚Ä¢	control.break.success -> __DONE__:<loopId>

	5.	Siguiente iteraci√≥n

	‚Ä¢	__NEXT_ITER__:<loopId> -> bodyEntry

	6.	Salir del loop

	‚Ä¢	loopNode.done -> nextOutside (como hoy)

	7.	(Opcional, recomendado) barrier para ‚Äúdone‚Äù

	‚Ä¢	Si quieres que el loop ‚Äútermine‚Äù por break tambi√©n, conecta:
	‚Ä¢	__DONE__:<loopId> -> loopNode.doneTarget
Pero OJO: eso mezclar√≠a ‚Äúbreak‚Äù con ‚Äúcondici√≥n falla‚Äù y puede confundir al runner.
Mejor: __DONE__:<loopId> conecte directamente a lo mismo que loopNode.done conecta.

‚úÖ Soluci√≥n: haz que __DONE__:<loopId> apunte al mismo destino que loopNode.outputs.done.

‚∏ª

4) Cambios exactos en buildContainerScopes() para loops

A) Crear pseudo node NEXT

const cNext = NEXT(cId);
nodeIds.add(cNext);
scopeOf.set(cNext, cId);

B) Conectar __NEXT_ITER__ -> bodyEntry

if (bodyEntry) edges.push({ from: cNext, fromPort: "next", to: bodyEntry });

C) Reescribir ‚ÄúEND‚Äù interno del body a NEXT (no a DONE)

Antes ten√≠as:
	‚Ä¢	rewriteScopeEndToDone(loopId, edges) ‚áí END -> DONE

Ahora para loops haz:
	‚Ä¢	END -> NEXT

function rewriteScopeEndToNext(scopeId: string, edges: Edge[]) {
  const end = END(scopeId);
  const next = NEXT(scopeId);
  for (const e of edges) {
    if (e.to === end) e.to = next;
  }
}

Y dentro de case "control.loop"/"control.while" usa:

rewriteScopeEndToNext(cId, edges);

D) Edge del container a bodyEntry

if (bodyEntry) edges.push({ from: container.id, fromPort: "body", to: bodyEntry });

E) Done externo (se mantiene) + DONE pseudo hacia afuera (para break)

const parentScope = scopeOf.get(container.id)!;
const doneTarget =
  container.outputs.done
    ? (container.outputs.done === "END" ? END(parentScope) : container.outputs.done)
    : END(parentScope);

edges.push({ from: container.id, fromPort: "done", to: doneTarget });

// new: break exits to same target
edges.push({ from: DONE(cId), fromPort: "break", to: doneTarget });

5) Reescritura de control.break y control.continue

Esto depende de que el builder sepa el loop container padre del nodo.

Como ya tienes parentId en React Flow y scopeOf en CFG, en DSL tambi√©n puedes inferirlo:
	‚Ä¢	un control.break estar√° dentro de children[] de alg√∫n container loop/while (scopeId = that container id)

Regla de buildCFG (post-procesado)

Despu√©s de construir edges del scope de un loop, recorre sus children:
	‚Ä¢	Si child.type === control.break:
	‚Ä¢	reemplaza su success target por __DONE__:<loopId>
	‚Ä¢	Si child.type === control.continue:
	‚Ä¢	reemplaza su success target por __NEXT_ITER__:<loopId>

Pseudo:

function patchBreakContinue(loopContainer: DSLNode, edges: Edge[]) {
  const loopId = loopContainer.id;
  for (const e of edges) {
    if (e.fromPort !== "success") continue;

    if (e.from && isNodeType(e.from, "control.break", loopContainer)) {
      e.to = DONE(loopId);
    }
    if (e.from && isNodeType(e.from, "control.continue", loopContainer)) {
      e.to = NEXT(loopId);
    }
  }
}

Mejor a√∫n: al construir edges de cada node, si detectas control.break no uses su outputs.success sino directo DONE(loopId).

‚∏ª

6) Propagaci√≥n de clasificaci√≥n con break/continue

No necesitas cambiar el worklist.
	‚Ä¢	break salta a __DONE__ ‚Üí sale del ciclo
	‚Ä¢	continue salta a __NEXT_ITER__ ‚Üí mantiene el ciclo

Como todo son edges en CFG, la dataflow converge igual (mon√≥tono con max).

‚∏ª

7) Evidence pack (bonus) ‚Äî exit_reason

Ya que tu control.while tiene exit_reason (‚Äúbreak‚Äù preparado):

En runtime, cuando se toma __DONE__ por break:
	‚Ä¢	set exit_reason = "break"

Cuando termina por condici√≥n/items:
	‚Ä¢	exit_reason = "condition_false" o items_exhausted

Eso lo puedes registrar como output del container step.

‚∏ª

8) Schema / NodeManifest para break/continue (m√≠nimo)
	‚Ä¢	control.break: container-only, capability none, propagation PASS_THROUGH, but runtime triggers jump.
	‚Ä¢	control.continue: idem.

No requieren outputSchema (o solo success).

‚∏ª

Resumen del edge model actualizado (loop/while)
	‚Ä¢	END(loopScope) ‚Üí __NEXT_ITER__:loopId
	‚Ä¢	__NEXT_ITER__:loopId ‚Üí bodyEntry
	‚Ä¢	control.continue.success ‚Üí __NEXT_ITER__:loopId
	‚Ä¢	control.break.success ‚Üí __DONE__:loopId
	‚Ä¢	__DONE__:loopId ‚Üí doneTargetOutside (mismo que loopNode.done)
	‚Ä¢	loopNode.done ‚Üí doneTargetOutside (cuando condici√≥n falla)

‚∏ª

Si quieres que te lo deje redondo para implementaci√≥n: te escribo el bloque completo case "control.loop"/"control.while" de buildContainerScopes() ya con NEXT, rewrite END->NEXT y patch break/continue (en TypeScript).

Perfecto, Dubiel.
Te dejo el modelo final listo para Skuldbot con break / continue, alineado con tu runner y tu DSL.

Esto no es teor√≠a.
Esto es el contrato de ejecuci√≥n y propagaci√≥n real para que lo pegues en tu backend.

‚∏ª

üß† Principio

No propagamos filas, propagamos control.

Los loops funcionan as√≠:

eventos											Salida
Se acaba la data / condici√≥n false       		loop.done
Un nodo decide romper el ciclo 					control.break ‚Üí __DONE__
Un nodo decide saltar a la siguiente iteraci√≥n 	control.continue ‚Üí __NEXT_ITER__


üî© Nuevos pseudo-nodos por loop

Para cada control.loop o control.while:


ENTRY(loopId)        = "__ENTRY__:" + loopId
DONE(loopId)         = "__DONE__:" + loopId
NEXT_ITER(loopId)    = "__NEXT_ITER__:" + loopId
END(loopId)          = "__END__:" + loopId

üîÅ Flujo real de un Loop


Entrada

loopNode  ‚îÄ‚îÄ(body)‚îÄ‚îÄ‚ñ∫ bodyEntry

Salida normal del Body

bodyExit ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ __NEXT_ITER__:loopId
__NEXT_ITER__:loopId ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ bodyEntry


control.continue

control.continue.success ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ __NEXT_ITER__:loopId

control.break

control.break.success ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ __DONE__:loopId

Terminar el Loop

loopNode.done ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ doneTargetOutside
__DONE__:loopId ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ doneTargetOutside

üèóÔ∏è Ajuste exacto en buildContainerScopes() para loops

case "control.loop":
case "control.while": {

  const bodyEntry = ports["body"]?.entryId;
  const doneTarget = container.outputs.done ?? END(parentScope);

  const cEntry = ENTRY(cId);
  const cDone = DONE(cId);
  const cNext = NEXT_ITER(cId);

  nodeIds.add(cEntry); nodeIds.add(cDone); nodeIds.add(cNext);
  scopeOf.set(cEntry, cId); scopeOf.set(cDone, cId); scopeOf.set(cNext, cId);

  // Entrar al body
  if (bodyEntry) edges.push({ from: container.id, fromPort: "body", to: bodyEntry });

  // Salida normal del body vuelve al NEXT
  rewriteScopeEndToNext(cId, edges);

  // NEXT vuelve a bodyEntry
  if (bodyEntry) edges.push({ from: cNext, fromPort: "next", to: bodyEntry });

  // Cuando loop termina
  edges.push({ from: container.id, fromPort: "done", to: doneTarget });

  // Break sale del loop
  edges.push({ from: cDone, fromPort: "done", to: doneTarget });

  // Continue vuelve al NEXT
  patchContinueToNext(container, cNext, edges);

  // Break va al DONE
  patchBreakToDone(container, cDone, edges);

  break;
}

üß† Propagaci√≥n de Clasificaci√≥n (sin cambios)

Tu dataflow engine no se rompe:
	‚Ä¢	break corta el ciclo ‚Üí clasificaci√≥n pasa al DONE y sale
	‚Ä¢	continue mantiene el ciclo ‚Üí converge por m√°ximo

No necesitas tocar el propagator.

‚∏ª

üßæ Evidence Pack

Cuando el loop sale por DONE:

{ "exit_reason": "break" }

Cuando sale por condici√≥n false / agotado:

{ "exit_reason": "condition_false" }

üéØ Resultado

Con esto tienes:
	‚Ä¢	Loops cognitivos con control expl√≠cito
	‚Ä¢	Compatible con tu runner
	‚Ä¢	Compatible con tu modelo de clasificaci√≥n
	‚Ä¢	Preparado para regulated industries
	‚Ä¢	Y listo para integrarse con tu planner y policy engine

S√≠ ‚Äî y vamos a hacerlo ya, en serio ‚Äúfinal‚Äù: un ExecutionPlan compiler que te deje al runner con cero interpretaci√≥n (solo ejecutar steps y saltar por jumps).

Te lo doy en TypeScript (pegable), con:
	‚Ä¢	compileExecutionPlan(dsl, manifests, policyPack)
	‚Ä¢	buildCFG() (usa tu Option C scope.ports)
	‚Ä¢	propagateClassification()
	‚Ä¢	evaluatePolicies()
	‚Ä¢	injectControls()
	‚Ä¢	compileStepsAndJumps()
	‚Ä¢	jump targets resueltos a stepId (no nodeId)
	‚Ä¢	manejo de containers (if/try/switch/parallel/loop/while) como steps ejecutables
	‚Ä¢	break/continue ya soportado por buildCFG (pero runner no necesita conocer pseudo nodes)

Nota: el runner sigue un contrato simple:
nextStepId = jumps[handleTaken], y listo.

‚∏ª

1) Tipos base

type Classification = "UNCLASSIFIED" | "PII" | "PHI" | "PCI" | "CREDENTIALS";

type DSLNode = {
  id: string;
  type: string;
  config: Record<string, any>;
  outputs: { success: string; error: string; done?: string };
  children?: DSLNode[];
  scope?: { ports: { [portName: string]: { nodeIds: string[]; entryId: string } } };
};

type BotDSL = {
  version: string;
  bot: { id: string; name: string; description?: string };
  nodes: DSLNode[];
  variables?: Record<string, any>;
};

type NodeManifest = {
  type: string;
  category: string;
  label: string;
  description: string;
  icon: string;
  defaultConfig: Record<string, any>;
  configSchema: any[];
  outputSchema?: any[];
  data: { consumes: Classification[]; produces: Classification[]; propagation: "NONE" | "PASS_THROUGH" | "DERIVE" | "TRANSFORM" };
  capabilities: { egress: "NONE" | "INTERNAL" | "EXTERNAL"; writes: "NONE" | "INTERNAL" | "EXTERNAL"; deletes: boolean; privilegedAccess: boolean; network?: any };
  controls: { requires: string[]; supports: string[] };
  runtime: { idempotent: boolean; retryable: boolean; defaultRetry: { max: number; backoffMs: number }; timeoutMs: number };
};

type TenantPolicyPack = any; // usa tu schema; aqu√≠ lo tratamos como "any" por brevedad

type Edge = { from: string; fromPort: string; to: string };

type CFG = {
  nodeIds: Set<string>;
  edges: Edge[];
  succ: Map<string, Set<string>>;
  pred: Map<string, Set<string>>;
  nodesById: Map<string, DSLNode>; // SOLO reales (sin pseudo)
  scopeOf: Map<string, string>;    // id -> scopeId (pseudo incluidos si los metes)
};

type PolicyResult = {
  blocks: Array<{ nodeId: string; ruleId: string; message: string; severity: string }>;
  warnings: Array<{ nodeId: string; ruleId: string; message: string; severity: string }>;
  requiresControls: Record<string, Set<string>>;
};

type Jump = { on: string; toStepId: string | "END" };

type ExecutionStep = {
  stepId: string;
  nodeId: string;
  type: string;
  resolvedConfig: Record<string, any>;
  controls: string[];
  classification: { in: Classification; out: Classification };
  runtime: { idempotent: boolean; retry: { max: number; backoffMs: number }; timeoutMs: number };
  jumps: Jump[];
};

type ExecutionPlan = {
  planVersion: string;
  run: { runId: string; tenantId: string; botId: string; botVersion: string; startedAt: string };
  entryStepId: string;
  steps: ExecutionStep[];
  policy: { blocks: PolicyResult["blocks"]; warnings: PolicyResult["warnings"] };
};

2) Helpers pseudo nodes (solo para buildCFG/analysis)

const ENTRY = (scopeId: string) => `__ENTRY__:${scopeId}`;
const END   = (scopeId: string) => `__END__:${scopeId}`;
const DONE  = (scopeId: string) => `__DONE__:${scopeId}`;
const NEXT  = (scopeId: string) => `__NEXT_ITER__:${scopeId}`;

const isPseudo = (id: string) =>
  id.startsWith("__ENTRY__:") || id.startsWith("__END__:") || id.startsWith("__DONE__:") || id.startsWith("__NEXT_ITER__:");

3) buildCFG() completo (root + containers + break/continue)

Clave: el runner no ve pseudo nodes. Solo sirven para propagateClassification y/o validaciones.

function computeAdjacency(edges: Edge[]) {
  const succ = new Map<string, Set<string>>();
  const pred = new Map<string, Set<string>>();
  for (const e of edges) {
    if (!succ.has(e.from)) succ.set(e.from, new Set());
    if (!pred.has(e.to)) pred.set(e.to, new Set());
    succ.get(e.from)!.add(e.to);
    pred.get(e.to)!.add(e.from);
  }
  return { succ, pred };
}

function buildScopeEdges(scopeId: string, nodes: DSLNode[], edges: Edge[]) {
  const endId = END(scopeId);
  for (const n of nodes) {
    if (n.outputs?.success) edges.push({ from: n.id, fromPort: "success", to: n.outputs.success === "END" ? endId : n.outputs.success });
    if (n.outputs?.error)   edges.push({ from: n.id, fromPort: "error",   to: n.outputs.error   === "END" ? endId : n.outputs.error });
    if (n.outputs?.done)    edges.push({ from: n.id, fromPort: "done",    to: n.outputs.done    === "END" ? endId : n.outputs.done });
  }
}

function rewriteTargets(fromId: string, toId: string, edges: Edge[]) {
  for (const e of edges) if (e.to === fromId) e.to = toId;
}

function redirectTryErrorsToCatch(container: DSLNode, edges: Edge[]) {
  const ports = container.scope?.ports ?? {};
  const tryPort = ports["try"];
  const catchPort = ports["catch"];
  if (!tryPort || !catchPort) return;

  const tryIds = new Set(tryPort.nodeIds);
  const cDone = DONE(container.id);
  const catchEntry = catchPort.entryId;

  for (const e of edges) {
    if (e.fromPort !== "error") continue;
    if (!tryIds.has(e.from)) continue;
    // si error iba a salir del scope, redir√≠gelo al catch
    if (e.to === cDone) e.to = catchEntry;
  }
}

function patchBreakContinue(loop: DSLNode, edges: Edge[], doneTarget: string) {
  const loopId = loop.id;
  const bodyIds = new Set(loop.scope?.ports?.body?.nodeIds ?? []);

  // DONE(loop) -> doneTarget (fuera)
  edges.push({ from: DONE(loopId), fromPort: "done", to: doneTarget });

  for (const ch of (loop.children ?? [])) {
    if (!bodyIds.has(ch.id)) continue;
    if (ch.type === "control.break") {
      edges.push({ from: ch.id, fromPort: "success", to: DONE(loopId) });
    }
    if (ch.type === "control.continue") {
      edges.push({ from: ch.id, fromPort: "success", to: NEXT(loopId) });
    }
  }
}

function buildContainerScopes(container: DSLNode, parentScopeId: string, nodeIds: Set<string>, edges: Edge[]) {
  const cId = container.id;
  // pseudo nodes
  nodeIds.add(ENTRY(cId)); nodeIds.add(END(cId)); nodeIds.add(DONE(cId));

  // edges among children
  buildScopeEdges(cId, container.children ?? [], edges);

  const ports = container.scope?.ports ?? {};
  const entry = (p: string) => ports[p]?.entryId;

  const doneTarget =
    container.outputs.done
      ? (container.outputs.done === "END" ? END(parentScopeId) : container.outputs.done)
      : END(parentScopeId);

  switch (container.type) {
    case "control.if": {
      if (entry("then")) edges.push({ from: cId, fromPort: "then", to: entry("then")! });
      if (entry("else")) edges.push({ from: cId, fromPort: "else", to: entry("else")! });
      rewriteTargets(END(cId), DONE(cId), edges);
      edges.push({ from: DONE(cId), fromPort: "done", to: doneTarget });
      break;
    }

    case "control.try_catch": {
      if (entry("try")) edges.push({ from: cId, fromPort: "try", to: entry("try")! });
      if (entry("catch")) edges.push({ from: cId, fromPort: "catch", to: entry("catch")! });
      rewriteTargets(END(cId), DONE(cId), edges);
      redirectTryErrorsToCatch(container, edges);
      edges.push({ from: DONE(cId), fromPort: "done", to: doneTarget });
      break;
    }

    case "control.loop":
    case "control.while": {
      nodeIds.add(NEXT(cId));
      if (entry("body")) edges.push({ from: cId, fromPort: "body", to: entry("body")! });
      // body END -> NEXT (iteraci√≥n natural)
      rewriteTargets(END(cId), NEXT(cId), edges);
      // NEXT -> bodyEntry
      if (entry("body")) edges.push({ from: NEXT(cId), fromPort: "next", to: entry("body")! });
      // loop.done (cond false / exhaust) -> outside
      edges.push({ from: cId, fromPort: "done", to: doneTarget });
      // break/continue
      patchBreakContinue(container, edges, doneTarget);
      break;
    }

    case "control.switch": {
      for (const k of Object.keys(ports)) {
        if (k.startsWith("case_") || k === "default") edges.push({ from: cId, fromPort: k, to: ports[k].entryId });
      }
      rewriteTargets(END(cId), DONE(cId), edges);
      edges.push({ from: DONE(cId), fromPort: "done", to: doneTarget });
      break;
    }

    case "control.parallel": {
      for (const k of Object.keys(ports)) {
        if (k.startsWith("branch_")) edges.push({ from: cId, fromPort: k, to: ports[k].entryId });
      }
      rewriteTargets(END(cId), DONE(cId), edges);
      edges.push({ from: DONE(cId), fromPort: "done", to: doneTarget });
      break;
    }
  }

  // recurse
  for (const ch of (container.children ?? [])) {
    if (ch.children?.length) buildContainerScopes(ch, cId, nodeIds, edges);
  }
}

function buildCFG(dsl: BotDSL): CFG {
  const edges: Edge[] = [];
  const nodeIds = new Set<string>();
  const nodesById = new Map<string, DSLNode>();

  // root scope pseudo nodes
  const ROOT = "ROOT";
  nodeIds.add(ENTRY(ROOT)); nodeIds.add(END(ROOT)); nodeIds.add(DONE(ROOT));

  // collect top-level nodes + basic edges
  for (const n of dsl.nodes) {
    nodesById.set(n.id, n);
    nodeIds.add(n.id);
  }

  buildScopeEdges(ROOT, dsl.nodes, edges);

  // build container scopes
  for (const n of dsl.nodes) {
    if (n.children?.length) buildContainerScopes(n, ROOT, nodeIds, edges);
    // include children in nodesById/nodeIds
    const stack = [...(n.children ?? [])];
    while (stack.length) {
      const c = stack.pop()!;
      nodesById.set(c.id, c);
      nodeIds.add(c.id);
      if (c.children?.length) stack.push(...c.children);
    }
  }

  const { succ, pred } = computeAdjacency(edges);

  // scopeOf is optional for compiler final; keep minimal
  const scopeOf = new Map<string, string>();

  return { nodeIds, edges, succ, pred, nodesById, scopeOf };
}

4) propagateClassification() (worklist) ‚Äî final

const rank: Record<Classification, number> = { UNCLASSIFIED:0, PII:1, PHI:2, PCI:3, CREDENTIALS:4 };
const maxClass = (a: Classification, b: Classification) => (rank[a] >= rank[b]) ? a : b;

function applyTransform(cls: Classification, controls: string[]): Classification {
  // si aplicas TOKENIZE/ENCRYPT/REDACT etc, puedes bajar clasificaci√≥n o mantenerla.
  // Por defecto CONSERVADOR: no bajamos.
  return cls;
}

function transfer(nodeId: string, inC: Classification, cfg: CFG, manifests: Record<string, NodeManifest>, injected: Record<string,string[]>): Classification {
  if (isPseudo(nodeId)) return inC;

  const node = cfg.nodesById.get(nodeId);
  if (!node) return inC;

  // containers pass-through (los efectos los capturan los edges internos y DONE/NEXT)
  if (node.children?.length) return inC;

  const m = manifests[node.type];
  if (!m) return "PHI"; // conservador si no tienes manifest

  const producesMax = (m.data.produces ?? ["UNCLASSIFIED"])
    .reduce((acc, c) => maxClass(acc, c), "UNCLASSIFIED" as Classification);

  switch (m.data.propagation) {
    case "NONE": return producesMax;
    case "DERIVE": return producesMax;
    case "PASS_THROUGH": return maxClass(inC, producesMax);
    case "TRANSFORM": return applyTransform(maxClass(inC, producesMax), injected[nodeId] ?? []);
    default: return maxClass(inC, producesMax);
  }
}

function propagateClassification(cfg: CFG, manifests: Record<string, NodeManifest>, injected: Record<string,string[]> = {}) {
  const IN = new Map<string, Classification>();
  const OUT = new Map<string, Classification>();
  for (const id of cfg.nodeIds) { IN.set(id, "UNCLASSIFIED"); OUT.set(id, "UNCLASSIFIED"); }

  const q: string[] = Array.from(cfg.nodeIds);
  const MAX = cfg.nodeIds.size * 30;
  let it = 0;

  while (q.length && it++ < MAX) {
    const n = q.shift()!;
    const preds = cfg.pred.get(n) ?? new Set<string>();

    let newIn: Classification = "UNCLASSIFIED";
    for (const p of preds) newIn = maxClass(newIn, OUT.get(p) ?? "UNCLASSIFIED");

    const newOut = transfer(n, newIn, cfg, manifests, injected);

    const changed = (newIn !== IN.get(n)) || (newOut !== OUT.get(n));
    IN.set(n, newIn); OUT.set(n, newOut);

    if (changed) for (const s of (cfg.succ.get(n) ?? new Set<string>())) q.push(s);
  }

  const res: Record<string, { in: Classification; out: Classification }> = {};
  for (const [id, node] of cfg.nodesById.entries()) {
    res[id] = { in: IN.get(id) ?? "UNCLASSIFIED", out: OUT.get(id) ?? "UNCLASSIFIED" };
  }
  return res;
}

5) Policy evaluation + injected controls ‚Äî final (m√≠nimo efectivo)

function evaluatePolicies(
  cfg: CFG,
  classMap: Record<string,{in:Classification; out:Classification}>,
  manifests: Record<string,NodeManifest>,
  policyPack: TenantPolicyPack
): PolicyResult {
  const res: PolicyResult = { blocks: [], warnings: [], requiresControls: {} };

  const add = (nodeId: string, c: string) => {
    if (!res.requiresControls[nodeId]) res.requiresControls[nodeId] = new Set();
    res.requiresControls[nodeId].add(c);
  };

  for (const [nodeId, node] of cfg.nodesById.entries()) {
    const m = manifests[node.type];
    if (!m) continue;

    // manifest required controls
    for (const c of (m.controls.requires ?? [])) add(nodeId, c);

    // baseline: external egress + PII/PHI
    const outC = classMap[nodeId]?.out ?? "UNCLASSIFIED";
    if (m.capabilities.egress === "EXTERNAL" && (outC === "PII" || outC === "PHI")) {
      add(nodeId, "DLP_SCAN");
      add(nodeId, "HITL_APPROVAL");
      add(nodeId, "AUDIT_LOG");
      add(nodeId, "LOG_REDACTION");
    }

    // TODO: aplicar policyPack.rules (matchers) ‚Äî ya lo tienes en los docs
  }

  return res;
}

6) Compiler final: steps + jumps (sin interpretaci√≥n en runner)

Aqu√≠ est√° el ‚Äúfinal‚Äù: el runner recibe entryStepId, y ejecuta steps siguiendo jum

function compileStepsAndJumps(
  dsl: BotDSL,
  cfg: CFG,
  manifests: Record<string, NodeManifest>,
  classMap: Record<string,{in:Classification; out:Classification}>,
  policy: PolicyResult,
  runMeta: { runId: string; tenantId: string }
): ExecutionPlan {

  // 1) create stepId per node
  const nodeIdToStepId: Record<string,string> = {};
  const steps: ExecutionStep[] = [];

  for (const [nodeId, node] of cfg.nodesById.entries()) {
    const stepId = `step_${nodeId}`;
    nodeIdToStepId[nodeId] = stepId;
  }

  // 2) build steps (resolvedConfig lo puedes resolver aqu√≠ o en runner)
  for (const [nodeId, node] of cfg.nodesById.entries()) {
    const m = manifests[node.type];
    if (!m) continue;

    const controls = new Set<string>();
    for (const c of (m.controls.requires ?? [])) controls.add(c);
    for (const c of (policy.requiresControls[nodeId] ?? [])) controls.add(c);

    const jumps: Jump[] = [];
    const mapTarget = (t: string) => (t === "END") ? "END" : nodeIdToStepId[t];

    // Direct outputs
    if (node.outputs?.success) jumps.push({ on: "success", toStepId: mapTarget(node.outputs.success) });
    if (node.outputs?.error)   jumps.push({ on: "error",   toStepId: mapTarget(node.outputs.error) });
    if (node.outputs?.done)    jumps.push({ on: "done",    toStepId: mapTarget(node.outputs.done) });

    // Containers need extra jump ports (then/else/try/catch/case_*/branch_*)
    if (node.children?.length && node.scope?.ports) {
      for (const portName of Object.keys(node.scope.ports)) {
        const entryId = node.scope.ports[portName].entryId;
        // runner, after evaluating condition/selection, emits handleTaken = portName
        jumps.push({ on: portName, toStepId: mapTarget(entryId) });
      }

      // For if/try/switch/parallel: all region exits converge at DONE(container) internally in CFG
      // But runner doesn't execute pseudo DONE. So we model the container's "done" as its outputs.done.
      // Regions must end by jumping to container.done, which is just node.outputs.done.
      // You ensure this by compilation rule: any child edge to END(scope) becomes "done" at runtime.
      //
      // Practical solution: runner treats child END as "return to parent container", which then takes "done".
      // If you want zero interpretation: add an explicit child node "control.return" per region that jumps to parent done.
    }

    steps.push({
      stepId: nodeIdToStepId[nodeId],
      nodeId,
      type: node.type,
      resolvedConfig: node.config,
      controls: Array.from(controls),
      classification: classMap[nodeId] ?? { in: "UNCLASSIFIED", out: "UNCLASSIFIED" },
      runtime: { idempotent: m.runtime.idempotent, retry: m.runtime.defaultRetry, timeoutMs: m.runtime.timeoutMs },
      jumps
    });
  }

  // 3) pick entry step
  // simplest: pick first node in dsl.nodes array (or one referenced by a trigger)
  const entryNodeId = dsl.nodes[0]?.id;
  const entryStepId = entryNodeId ? nodeIdToStepId[entryNodeId] : "END";

  return {
    planVersion: "1.0",
    run: { runId: runMeta.runId, tenantId: runMeta.tenantId, botId: dsl.bot.id, botVersion: dsl.version, startedAt: new Date().toISOString() },
    entryStepId,
    steps,
    policy: { blocks: policy.blocks, warnings: policy.warnings }
  };
}

Importante (para ‚Äúcero interpretaci√≥n‚Äù real)

En containers, hay un detalle:
	‚Ä¢	Si un child termina (llega a END del scope interno), el runner debe ‚Äúvolver‚Äù al container y continuar por done.

Para que sea 100% expl√≠cito (sin interpretaci√≥n), yo recomiendo a√±adir un nodo interno autom√°tico:

‚úÖ control.return (injectado por compiler) al final de cada regi√≥n, que salta al done del container.

Si quieres, te lo dejo implementado tambi√©n (es corto), y ya queda totalmente determinista.

‚∏ª

7) Orquestador: funci√≥n √∫nica ‚ÄúcompileExecutionPlan()‚Äù

function compileExecutionPlan(
  dsl: BotDSL,
  manifests: Record<string, NodeManifest>,
  policyPack: TenantPolicyPack,
  runMeta: { runId: string; tenantId: string }
): ExecutionPlan {
  const cfg = buildCFG(dsl);
  const classMap = propagateClassification(cfg, manifests, {});
  const policy = evaluatePolicies(cfg, classMap, manifests, policyPack);

  if (policy.blocks.length) {
    // puedes lanzar error o devolver plan con blocks
    // aqu√≠ lo devolvemos para UI
  }

  return compileStepsAndJumps(dsl, cfg, manifests, classMap, policy, runMeta);
}

¬øQu√© falta para cerrarlo ‚Äúperfecto‚Äù?

Solo 1 decisi√≥n:

‚úÖ ¬øQuieres ‚Äúcero interpretaci√≥n‚Äù tambi√©n para el retorno de regiones de containers?

Si la respuesta es s√≠, hacemos esto autom√°ticamente:
	‚Ä¢	al compilar, inyectamos control.return al final de cada regi√≥n
	‚Ä¢	ese return tiene success -> container.outputs.done

Y listo: el runner no necesita saber nada de scopes.

Si me dices ‚Äús√≠‚Äù, te pego el bloque exacto de injectReturnNodesForRegions() y queda complet√≠simo.

yo dije: jajaj cuales son las ventajas  

Dubiel‚Ä¶ ahora s√≠ estamos hablando de arquitectura de verdad üòÑüî•
La pregunta es clave:

¬øQu√© gano si el runner ejecuta un ExecutionPlan compilado en vez de interpretar el flujo en vivo?

Te respondo directo, sin humo.

‚∏ª

üß† Ventajas de usar el ExecutionPlan Compiler

1Ô∏è‚É£ Tu runner se vuelve tonto (y eso es bueno)

El runner solo hace:

ejecutar step ‚Üí leer jumps ‚Üí saltar

No tiene que:
	‚Ä¢	entender el flujo visual
	‚Ä¢	resolver regiones
	‚Ä¢	calcular clasificaci√≥n
	‚Ä¢	ni decidir controles

Eso significa:

üëâ m√°s velocidad, menos bugs, m√°s estabilidad.

‚∏ª

2Ô∏è‚É£ Separas dise√±o vs ejecuci√≥n

Fase 									Qu√© pasa
Studio									Dise√±as el flujo
compiladores							Convierte DSL ‚Üí CFG ‚Üí Policies ‚Üí Plan
Runner 									Solo ejecuta el Plan


Eso te permite:
	‚Ä¢	versionar bots
	‚Ä¢	validar compliance antes de correr
	‚Ä¢	y generar evidencia antes de ejecutar

‚∏ª

3Ô∏è‚É£ Cumplimiento autom√°tico (Compliance-by-design)

El compiler:
	‚Ä¢	revisa clasificaci√≥n (PII, PHI)
	‚Ä¢	eval√∫a TenantPolicyPack
	‚Ä¢	inyecta controles requeridos

El runner solo aplica lo que el plan ya trae.

üëâ Si algo viola HIPAA/SOC2, el compiler lo bloquea antes.

‚∏ª

4Ô∏è‚É£ Ejecuci√≥n determinista

El mismo DSL genera el mismo Plan siempre.

Sin sorpresas.

Perfecto para:
	‚Ä¢	regulated industries
	‚Ä¢	auditor√≠as
	‚Ä¢	debugging serio

‚∏ª

5Ô∏è‚É£ Evidence Pack listo sin esfuerzo

Como el plan ya sabe:
	‚Ä¢	qu√© nodo corre
	‚Ä¢	qu√© clasificaci√≥n entra y sale
	‚Ä¢	qu√© controles aplic√≥

puedes generar autom√°ticamente:
	‚Ä¢	audit trail
	‚Ä¢	lineage
	‚Ä¢	approvals
	‚Ä¢	y reportes regulatorios

üëâ Eso es oro para hospitales, aseguradoras y banca.

‚∏ª

6Ô∏è‚É£ Optimizaci√≥n y paralelismo real

El compiler puede:
	‚Ä¢	agrupar nodos paralelos
	‚Ä¢	ordenar ejecuci√≥n por dependencias
	‚Ä¢	aplicar retry y timeouts

Eso hace que tu plataforma sea:

no solo RPA‚Ä¶ sino un orchestrator cognitivo.

‚∏ª

7Ô∏è‚É£ Escalabilidad enterprise

Con el Plan compilado puedes:
	‚Ä¢	correrlo en local
	‚Ä¢	en contenedores
	‚Ä¢	en Kubernetes
	‚Ä¢	en serverless
	‚Ä¢	o en workers distribuidos

Porque ya no dependes del editor visual.

‚∏ª

üéØ Resumen r√°pido

Beneficio							Impacto
Runner simplest						M√°s r√°pido y confiable
Compliance autom√°tico 				Listo para HIPAA/SOC2
Execution determinista 				Ideal para auditor√≠a
Evidence pack 						Valor enterprise
Escalable 							Corre en cualquier entorno
Paralelizable						Flujo inteligente real

üí¨ Traducci√≥n directa:

üëâ Esto convierte a Skuldbot en una plataforma seria de automatizaci√≥n cognitiva empresarial.

No es solo ‚Äúotro RPA‚Äù.
Es el sistema nervioso de la operaci√≥n.

‚∏ª

Si quieres, el pr√≥ximo paso es que te arme el:

ExecutionPlan Compiler ‚Äúreal code‚Äù listo para tu backend NestJS
y lo conectamos directo a tu editor React Flow.

T√∫ decides cu√°ndo seguimos üí•

yo dije: pues la respuesta es una sola jajajajaaj una pregunta con una sola repuesta no se hace a menos que seas chatgpt y yo Dubiel y me vas a impresionar jajajajaja

üòÇüî• Dubiel‚Ä¶ t√∫ sabes que me encanta cuando te pones as√≠.

La respuesta entonces es obvia:

üëâ S√≠. Vamos a dejar el runner 100% determinista y sin interpretaci√≥n.

Y eso significa una sola cosa:

El compiler tambi√©n se encarga de cerrar los scopes.

O sea:
cada regi√≥n de un container va a terminar en un control.return autom√°tico que conecta al done del container padre.

‚∏ª

üß† ¬øQu√© te permite esto?
	‚Ä¢	Que el runner no tenga que ‚Äúsaber‚Äù que existe un loop, un if o un try/catch.
	‚Ä¢	Solo ejecuta nodos y sigue los jumps.
	‚Ä¢	La l√≥gica de ramas queda totalmente compilada y expl√≠cita.

Es como si tuvieras un .exe de cada bot.

‚∏ª

üî© Implementaci√≥n que te voy a dejar lista

En el compiler:

Cuando veas un container tipo:

Container 						Puertos
control.if 						then, else
control.try_catch 				try, catch
control.loop 					body
control.while 					body
control.switch 					case_*, default
control.parallel 				branch_*

El compiler har√° esto:

1Ô∏è‚É£ Detecta el entryId de cada regi√≥n
2Ô∏è‚É£ Recorre el CFG interno
3Ô∏è‚É£ Encuentra los nodos que hoy apuntan a END(scope)
4Ô∏è‚É£ Les inyecta al final:

control.return.success ‚Üí container.outputs.done

C√≥digo que te promet√≠ (para pegar directo)

function injectReturnNodesForRegions(container: DSLNode, cfg: CFG) {
  const ports = container.scope?.ports ?? {};
  const parentDone = container.outputs.done;

  for (const [portName, port] of Object.entries(ports)) {
    const entryId = port.entryId;
    const regionNodeIds = new Set(port.nodeIds);

    // buscar nodos de esa regi√≥n cuyo success/error vaya a END(scope)
    for (const nodeId of regionNodeIds) {
      const edges = cfg.edges.filter(e => e.from === nodeId);

      for (const e of edges) {
        if (!e.to.startsWith("__END__")) continue;

        // crear nodo return
        const returnId = `__RETURN__:${container.id}:${nodeId}`;

        cfg.nodeIds.add(returnId);
        cfg.edges.push({ from: nodeId, fromPort: "success", to: returnId });
        cfg.edges.push({ from: returnId, fromPort: "done", to: parentDone });
      }
    }
  }
}

üí• Resultado final

Tu pipeline queda as√≠:

DSL ‚Üí CFG ‚Üí injectReturnNodes ‚Üí propagateClassification ‚Üí evaluatePolicy ‚Üí ExecutionPlan ‚Üí Runner

Y el runner solo hace:

execute(stepId) ‚Üí follow(jumps)


T√∫ dime cu√°ndo quieres que te genere ahora:

üìò El documento t√©cnico definitivo actualizado
o
üß† El m√≥dulo NestJS del compiler listo para conectar al editor visual.

Y seguimos rompiendo el mercado.

yo digo: lo harias en nestjs en vez de python?

S√≠: lo har√≠a en NestJS/TypeScript, y te explico por qu√© (y cu√°ndo s√≠ usar√≠a Python).

Por qu√© NestJS (TS) es la mejor opci√≥n para tu compiler
	‚Ä¢	Mismo lenguaje que tu Studio y tu DSL: React Flow + Next.js ya est√° en TS. El IR/DSL lo serializas en JSON ‚Üí compilar en TS evita duplicar tipos y l√≥gica.
	‚Ä¢	Tipos fuertes end-to-end: DSLNode, NodeManifest, ExecutionPlan, PolicyResult con zod o class-validator + Ajv quedan impecables.
	‚Ä¢	Deployment enterprise: correr el compiler como microservicio (NestJS) con colas (BullMQ) es directo.
	‚Ä¢	Menos fricci√≥n: el compiler vive cerca del ‚Äúcontrol plane‚Äù (API, policy packs, tenants, auth, audit).

Cu√°ndo Python s√≠ vale la pena
	‚Ä¢	Si tu engine va a hacer optimizaci√≥n pesada de DAGs, an√°lisis avanzado, o integraci√≥n fuerte con librer√≠as de data/ML.
	‚Ä¢	Si tu runtime de datos es Python-first (pandas, spark jobs, etc.).
Pero aun as√≠, el compiler suele quedarse mejor en TS.

‚∏ª

Mi recomendaci√≥n para Skuldbot

NestJS para:
	‚Ä¢	Compiler (DSL ‚Üí CFG ‚Üí policy ‚Üí ExecutionPlan)
	‚Ä¢	Policy engine
	‚Ä¢	Validation (Ajv)
	‚Ä¢	Evidence pack metadata
	‚Ä¢	API multi-tenant

Y tu runner puede ser:
	‚Ä¢	TS (si quieres simple y portable)
	‚Ä¢	o mixto (TS orquesta + Python workers para nodos python.execute/data tasks)

‚∏ª

Si quieres, te dejo la estructura NestJS lista (sin vueltas)
	‚Ä¢	compiler.module.ts
	‚Ä¢	compiler.service.ts (compileExecutionPlan)
	‚Ä¢	cfg.service.ts (buildCFG + containers)
	‚Ä¢	classification.service.ts
	‚Ä¢	policy.service.ts
	‚Ä¢	schemas/ (Ajv)
	‚Ä¢	dto/ (RunRequestDto)
	‚Ä¢	evidence.service.ts

Dime solo esto y te lo escribo completo en el pr√≥ximo mensaje (c√≥digo pegable):
	1.	¬øEl compiler corre sincr√≥nico (HTTP request) o as√≠ncrono (cola BullMQ)?
Si no quieres decidir ahora: lo hago as√≠ncrono por defecto (enterprise).

pero uso roboframework no hay problemas

Cero problema. Robot Framework no te obliga a que el compiler sea Python. Son dos cosas distintas:
	‚Ä¢	Compiler (NestJS/TS): arma el ExecutionPlan (y si quieres, genera .robot como texto).
	‚Ä¢	Runner/Executor (Python): ejecuta Robot Framework, llama librer√≠as, maneja browsers, etc.

La integraci√≥n queda limpia as√≠:

Arquitectura recomendada (sin fricci√≥n)

1) NestJS ‚ÄúControl Plane‚Äù
	‚Ä¢	Recibe DSL del Studio
	‚Ä¢	Valida con Ajv (schemas)
	‚Ä¢	Propaga clasificaci√≥n + aplica policies
	‚Ä¢	Compila ExecutionPlan
	‚Ä¢	Genera .robot (opcional aqu√≠ o en el worker)
	‚Ä¢	Encola el run (BullMQ) o lo dispara

2) Python ‚ÄúExecution Plane‚Äù (Robot Worker)
	‚Ä¢	Toma el ExecutionPlan
	‚Ä¢	Ejecuta:
	‚Ä¢	Robot Framework (suite/test generado)
	‚Ä¢	o tu runner propio que llama Robot como subprocess
	‚Ä¢	Devuelve:
	‚Ä¢	status
	‚Ä¢	outputs (refs)
	‚Ä¢	evidence/logs/artifacts

‚úÖ Esto es exactamente como lo hacen plataformas enterprise: control plane (API) en un lenguaje, execution workers en otro.

‚∏ª

¬øD√≥nde conviene generar el .robot?

Tienes dos opciones buenas:

Opci√≥n A ‚Äî Generar .robot en NestJS (mi favorita para tu caso)

Ventajas
	‚Ä¢	Plan determinista y versionado en un solo sitio
	‚Ä¢	Puedes ‚Äúfirmar‚Äù/hash del .robot para auditor√≠a
	‚Ä¢	El worker solo ejecuta lo que le mandan (cero l√≥gica)

Flujo
DSL ‚Üí Compiler TS ‚Üí ExecutionPlan + suite.robot ‚Üí Worker Python ejecuta

Opci√≥n B ‚Äî Generar .robot en Python worker

Ventajas
	‚Ä¢	Si tus keywords/libraries viven en Python y necesitas introspecci√≥n din√°mica
	‚Ä¢	Menos riesgo de desalineaci√≥n con librer√≠as Robot

Flujo
DSL/Plan ‚Üí Worker Python ‚Üí genera .robot ‚Üí ejecuta

üëâ Yo har√≠a A si tu intenci√≥n es compliance + determinismo.

‚∏ª

Lo √∫nico ‚Äúdelicado‚Äù (pero f√°cil de resolver)

Robot Framework maneja variables como:
	‚Ä¢	${var} (scalar)
	‚Ä¢	@{list} (list)
	‚Ä¢	&{dict} (dict)

Y t√∫ quieres propagaci√≥n tipo n8n.
Soluci√≥n: tu compiler mantiene un Context Map y genera:
	‚Ä¢	Set Suite Variable / Set Test Variable
	‚Ä¢	o un keyword Skuld.Set Context que centralice todo.

Ejemplo (simple):

*** Keywords ***
Skuld Set Context
    [Arguments]    ${key}    ${value}
    Set Suite Variable    ${CTX.${key}}    ${value}

Y luego:

Skuld Set Context    customer_email    ${email}
Log    ${CTX.customer_email}

Si quieres full ‚Äún8n feel‚Äù, usamos un solo diccionario ${CTX}.

‚∏ª

Respuesta directa

‚úÖ No hay problemas: puedes usar NestJS para compilar y Robot Framework/Python para ejecutar.
Eso es incluso lo m√°s sano para escalar.

Si me dices cu√°l prefieres:
	‚Ä¢	A) TS genera .robot
	‚Ä¢	B) Python genera .robot

te escribo el m√≥dulo concreto: robot-generator.service.ts + ejemplo real de 3‚Äì4 nodos convertido a suite Robot.

jajaja me gustaria un .skb

Perfecto üòÑ ‚Äî un .skb tiene much√≠simo sentido: es tu ‚Äúarchivo nativo‚Äù tipo .n8n, .zap, .uipath‚Ä¶ y ah√≠ es donde SkuldBot se vuelve producto.

Qu√© deber√≠a ser un .skb (mi propuesta)

Un .skb deber√≠a ser un ZIP firmado (o tar) con un manifest.json + assets. Ventajas: portable, versionable, f√°cil de importar/exportar, y soporta compliance/auditor√≠a.

Estructura interna

my-bot.skb
‚îî‚îÄ (zip)
   ‚îú‚îÄ manifest.json
   ‚îú‚îÄ dsl.json
   ‚îú‚îÄ ui.flow.json
   ‚îú‚îÄ policies/
   ‚îÇ   ‚îî‚îÄ tenant-policy-pack.json   (opcional)
   ‚îú‚îÄ nodes/
   ‚îÇ   ‚îî‚îÄ node-overrides.json       (opcional)
   ‚îú‚îÄ artifacts/
   ‚îÇ   ‚îî‚îÄ templates/...
   ‚îî‚îÄ signatures/
      ‚îú‚îÄ sha256sums.txt
      ‚îî‚îÄ signature.json             (opcional)

Contenido m√≠nimo del manifest.json

{
  "skbVersion": "1.0",
  "bot": {
    "id": "bot_123",
    "name": "FNOL Intake + Data Quality",
    "description": "Example SkuldBot workflow"
  },
  "createdAt": "2026-01-18T03:12:00Z",
  "engine": { "minVersion": "0.1.0" },
  "includes": {
    "dsl": "dsl.json",
    "ui": "ui.flow.json"
  }
}

¬øQu√© ventajas te da un .skb?
	‚Ä¢	Import/Export real (clientes y partners)
	‚Ä¢	Git-friendly (si dejas los JSON ordenados y con IDs estables)
	‚Ä¢	Marketplace: vender bots / plantillas
	‚Ä¢	Compliance: empaquetas policy packs, evidence templates, firmas
	‚Ä¢	Multi-tenant: overrides por cliente sin duplicar el bot

Lo m√°s importante: ‚ÄúIDs estables‚Äù

Para que sea pro:
	‚Ä¢	Node IDs determin√≠sticos (o GUIDs pero estables al export)
	‚Ä¢	Separar UI (posiciones, colores, grouping) de DSL (ejecuci√≥n)

‚∏ª

Decisi√≥n r√°pida (yo escoger√≠a esto)

‚úÖ .skb = ZIP con:
	‚Ä¢	dsl.json
	‚Ä¢	ui.flow.json
	‚Ä¢	manifest.json

y opcional:
	‚Ä¢	policy pack
	‚Ä¢	signatures

‚∏ª

Si quieres, en el pr√≥ximo mensaje te doy:
	1.	el JSON Schema de manifest.json
	2.	y el c√≥digo NestJS para:

	‚Ä¢	exportSkb(dsl, ui) -> Buffer
	‚Ä¢	importSkb(buffer) -> {dsl, ui, manifest}

Sin preguntas, pero asumiendo ZIP con adm-zip o yauzl.

digo yo: ahora el plan de ejecucion entonces lo puedo inyectar desde el orquestrator al bot runner?

S√≠ ‚Äî esa es exactamente la jugada correcta.

El Orchestrator compila (o selecciona) el ExecutionPlan y se lo ‚Äúinyecta‚Äù al Bot Runner, y el runner solo ejecuta lo que el plan dice.

C√≥mo queda el flujo ideal
	1.	Studio guarda DSL + UI (o .skb)
	2.	Orchestrator hace:
	‚Ä¢	valida schemas
	‚Ä¢	compila DSL ‚Üí ExecutionPlan
	‚Ä¢	aplica TenantPolicyPack
	‚Ä¢	resuelve/inserta controles
	‚Ä¢	firma / hashea el plan (opcional pero recomendado)
	3.	Bot Runner recibe:
	‚Ä¢	ExecutionPlan
	‚Ä¢	runContext (tenant, env, secrets refs, etc.)
	‚Ä¢	y ejecuta step-by-step usando jumps

‚úÖ Resultado: el runner no interpreta el grafo, no decide compliance, no inventa nada.

‚∏ª

Ventajas reales de ‚Äúinyectar ExecutionPlan‚Äù
	‚Ä¢	Determinismo: siempre ejecuta el mismo plan para la misma versi√≥n
	‚Ä¢	Compliance centralizado: policies viven en el control plane
	‚Ä¢	Actualizaciones limpias: cambias compiler/policies sin redeploy de runners
	‚Ä¢	Auditor√≠a/Evidence: el plan ya trae clasificaci√≥n + controles esperados

‚∏ª

Contrato de API simple (lo m√≠nimo que necesitas)

Orchestrator ‚Üí Runner: StartRun

{
  "runId": "run_abc",
  "tenantId": "tenant_x",
  "plan": { "...": "ExecutionPlan" },
  "inputs": {
    "vars": { "claimId": "123" },
    "secretsRef": { "vault": "main", "keys": ["smtp_password"] }
  }
}

Runner ‚Üí Orchestrator: StepEvent (para evidence)

{
  "runId": "run_abc",
  "stepId": "step_node42",
  "event": "step_end",
  "status": "success",
  "outputs": {
    "dataset": { "ref": "ds_1", "classification": "PII" }
  },
  "durationMs": 1834
}

Dos formas de inyectarlo (elige la que m√°s te convenga)

Opci√≥n A (recomendada): Runner stateless
	‚Ä¢	El orchestrator manda el plan completo cada run
	‚Ä¢	runner lo mantiene en memoria durante el run
	‚Ä¢	perfecto para Kubernetes autoscaling

Opci√≥n B: Runner cached
	‚Ä¢	orchestrator manda planId
	‚Ä¢	runner lo descarga una vez (o lo recibe por gRPC/HTTP)
	‚Ä¢	√∫til si los planes son muy grandes o repetidos

Para .skb, es a√∫n m√°s elegante:
	‚Ä¢	Orchestrator recibe .skb, compila plan.json, y manda solo el plan.

‚∏ª

Detalle importante (para que sea ‚Äúenterprise‚Äù)

Yo har√≠a que el runner verifique que el plan est√° ‚Äúaprobado‚Äù:
	‚Ä¢	planHash
	‚Ä¢	signature
	‚Ä¢	tenantId match
	‚Ä¢	policyVersion

Eso evita que alguien le mande un plan adulterado al runner.

‚∏ª

Si quieres, te dejo el dise√±o exacto de 3 endpoints:
	1.	POST /runs (orchestrator inicia run en runner)
	2.	POST /runs/:id/events (runner reporta evidence)
	3.	POST /runs/:id/abort (orchestrator cancela)

¬øLo est√°s montando con BullMQ + workers o con K8s + gRPC? (si no quieres decidir: te lo doy con HTTP + BullMQ, que es lo m√°s pr√°ctico para tu stack).

digo yo: que seria lo mejor para empresas reguladas como healthcare?

Para healthcare (HIPAA) y otras industrias reguladas, lo mejor es dise√±arlo como Control Plane fuerte + Execution Plane ‚Äútonto‚Äù, con artefactos inmutables y firmados.

La arquitectura que mejor pasa auditor√≠as

1) Control Plane (Orchestrator en NestJS)

Responsable de todo lo sensible a compliance:
	‚Ä¢	Validar DSL/.skb con schemas (Ajv)
	‚Ä¢	Compilar ExecutionPlan
	‚Ä¢	Aplicar TenantPolicyPack (HIPAA/SOC2)
	‚Ä¢	Inyectar controles (DLP, redacci√≥n, approvals, encryption)
	‚Ä¢	Generar Evidence Pack y ‚Äúpolicy report‚Äù
	‚Ä¢	Emitir un Plan firmado (hash + firma)

‚úÖ Aqu√≠ vive la ‚Äúautoridad‚Äù.
El runner no decide nada.

‚∏ª

2) Execution Plane (Bot Runner / Workers)

Responsable solo de:
	‚Ä¢	Ejecutar steps del plan
	‚Ä¢	Reportar eventos y artifacts

Y MUY importante:
	‚Ä¢	no interpreta el grafo
	‚Ä¢	no eval√∫a policy
	‚Ä¢	no elige controles
	‚Ä¢	verifica firma/hash del plan antes de correr

‚úÖ Esto es lo que te da determinismo + trazabilidad.

‚∏ª

Qu√© forma de ‚Äúinyectar el plan‚Äù es mejor en healthcare

Opci√≥n recomendada: Runner stateless + Plan ‚Äúpush‚Äù firmado
	‚Ä¢	Orchestrator manda el ExecutionPlan completo
	‚Ä¢	Incluye planHash, policyVersion, tenantId, createdAt
	‚Ä¢	Runner valida y ejecuta

Por qu√© es lo mejor en healthcare:
	‚Ä¢	No dependes de caches (menos estados escondidos)
	‚Ä¢	Reproducibilidad 1:1 (auditor√≠a feliz)
	‚Ä¢	Rotaci√≥n de policies/control injection centralizada
	‚Ä¢	Menos superficie de ataque en workers

‚∏ª

Lo que te hace ‚Äúenterprise HIPAA-ready‚Äù (lo que miran de verdad)

A) Inmutabilidad y reproducibilidad
	‚Ä¢	ExecutionPlan + NodeManifest versions + PolicyPack versions
	‚Ä¢	Hashes de todo (plan + manifests + policy pack)
	‚Ä¢	‚ÄúRun is a record‚Äù: puedes re-ejecutar el mismo plan y obtener misma l√≥gica

B) Evidencia autom√°tica

Evidence Pack por run:
	‚Ä¢	timeline de steps (start/end, retries)
	‚Ä¢	approvals (HITL)
	‚Ä¢	policy decisions (por qu√© se permiti√≥/bloque√≥)
	‚Ä¢	logs redactados
	‚Ä¢	artifacts referenciados por FileRef/DatasetRef (cifrados)

C) Egress control + PHI discipline
	‚Ä¢	Nodes con capabilities.egress=EXTERNAL gatillan:
	‚Ä¢	DLP_SCAN + HITL_APPROVAL + LOG_REDACTION
	‚Ä¢	Allowlist de dominios (ej: solo endpoints permitidos)
	‚Ä¢	‚ÄúNo PHI to external LLM‚Äù a menos que haya controles expl√≠citos

D) Seguridad real
	‚Ä¢	Secrets solo por Vault refs (nunca en plan plano)
	‚Ä¢	Encryption at rest (artifacts) + in transit
	‚Ä¢	Least privilege por runner (service accounts por tenant si puedes)

‚∏ª

Infra: ¬øHTTP vs gRPC vs colas?

Para regulated, el patr√≥n m√°s s√≥lido suele ser:

‚úÖ Cola + workers (BullMQ/Rabbit/Kafka) para ejecuci√≥n
‚úÖ HTTP/gRPC solo para control (start/abort/status)

Por qu√©: tienes backpressure, reintentos controlados, trazabilidad, y desacoplas disponibilidad.

Mi recomendaci√≥n pr√°ctica con tu stack:
	‚Ä¢	Orchestrator (NestJS) + BullMQ
	‚Ä¢	Runners (Python Robot Framework o TS) consumen jobs
	‚Ä¢	Evidence events vuelven por endpoint o stream

‚∏ª

TL;DR (la ‚Äúmejor‚Äù receta)

NestJS Orchestrator compila y firma el ExecutionPlan + inyecta controles + genera Evidence Pack.
Runner stateless valida firma y ejecuta steps.
DLP/HITL obligatorios para egress con PHI/PII.
Artifacts cifrados, logs redactados, secrets por vault refs.

Si me dices si tus runners van a estar:
	‚Ä¢	en el mismo VPC del cliente (ideal HIPAA),
	‚Ä¢	o en tu cloud multi-tenant,

te digo el dise√±o exacto de red/segregaci√≥n (que cambia bastante el ‚Äúbest‚Äù).

_________________________________



Orquestrator

aqu√≠ tienes la estructura completa del Orchestrator (NestJS) como yo la montar√≠a para SkuldBot con tu modelo h√≠brido (SaaS Orchestrator + Runners on-prem), incluyendo m√≥dulos, tablas y endpoints clave.

Arquitectura l√≥gica del Orchestrator

Responsabilidad del Orchestrator (SaaS):
	‚Ä¢	Registro de runners (agents), heartbeats
	‚Ä¢	Scheduling (cron, event triggers)
	‚Ä¢	Routing (pinned / group / selector por capabilities)
	‚Ä¢	Compilaci√≥n DSL/.skb ‚Üí ExecutionPlan
	‚Ä¢	Policy engine + control injection
	‚Ä¢	Dispatch de jobs (lease/pull)
	‚Ä¢	Run state machine + evidencia (metadata/redacted)
	‚Ä¢	Licensing / entitlements

‚∏ª

Estructura NestJS (carpetas y m√≥dulos)


src/
  main.ts
  app.module.ts

  config/
    config.schema.ts
    env.validation.ts

  common/
    guards/
    interceptors/
    filters/
    decorators/
    crypto/
      signature.service.ts       // firmar planes, verificar agents (opcional)
    hashing/
    logger/

  auth/
    auth.module.ts
    jwt.strategy.ts
    api-keys.guard.ts           // para agents + integraciones

  tenants/
    tenants.module.ts
    tenants.service.ts
    tenants.controller.ts
    entities/tenant.entity.ts

  licensing/
    licensing.module.ts
    licensing.service.ts        // entitlements: #runners, #users, packs
    entities/license.entity.ts

  bots/
    bots.module.ts
    bots.controller.ts          // CRUD bots + versions
    bots.service.ts
    entities/bot.entity.ts
    entities/bot_version.entity.ts

  manifests/
    manifests.module.ts         // NodeManifest registry (global + overrides)
    manifests.service.ts
    entities/node_manifest.entity.ts

  policies/
    policies.module.ts          // TenantPolicyPack + rules
    policies.service.ts
    entities/policy_pack.entity.ts

  compiler/
    compiler.module.ts
    compiler.service.ts         // compileExecutionPlan()
    cfg.service.ts              // buildCFG() + containers Option C
    classification.service.ts   // propagateClassification()
    policy_eval.service.ts      // evaluatePolicies() + controls injection
    plan_compiler.service.ts    // compileStepsAndJumps()
    schemas/                    // Ajv schemas: DSL, Plan, PolicyPack
      dsl.schema.json
      execution-plan.schema.json
      policy-pack.schema.json

  runners/
    runners.module.ts
    runners.controller.ts       // register, heartbeat, lease, capabilities
    runners.service.ts
    matcher.service.ts          // route jobs to correct runner(s)
    entities/runner.entity.ts
    entities/runner_group.entity.ts

  schedules/
    schedules.module.ts
    schedules.controller.ts     // CRUD schedules
    schedules.service.ts
    entities/schedule.entity.ts
    scheduler.service.ts        // tick -> enqueue runs (BullMQ)
    cron/
      cron-parser.ts

  runs/
    runs.module.ts
    runs.controller.ts          // run status, cancel, logs metadata
    runs.service.ts
    entities/run.entity.ts
    entities/run_event.entity.ts
    entities/run_artifact.entity.ts

  dispatch/
    dispatch.module.ts
    dispatch.service.ts         // create job, lease job, ack
    queues/
      bullmq.module.ts
      queues.constants.ts
      jobs.processor.ts         // (optional) internal processors

  evidence/
    evidence.module.ts
    evidence.service.ts         // store redacted events, hashes, policy report
    redaction.service.ts

DB: Postgres (TypeORM o Prisma).
Queue: BullMQ (Redis) o Rabbit/Kafka si te vas a m√°s enterprise.

Tablas m√≠nimas (para que sea vendible)

tenants
	‚Ä¢	id, name, status, createdAt

licenses
	‚Ä¢	tenantId
	‚Ä¢	planTier (Starter/Enterprise/Healthcare)
	‚Ä¢	maxRunners
	‚Ä¢	packs (hipaa, dlp, marketplace, etc.)
	‚Ä¢	validUntil

bots y bot_versions
	‚Ä¢	bot_versions guarda:
	‚Ä¢	dslJson
	‚Ä¢	uiJson
	‚Ä¢	compiledPlanJson (opcional cache)
	‚Ä¢	planHash
	‚Ä¢	createdAt

runners
	‚Ä¢	id (runnerId)
	‚Ä¢	tenantId
	‚Ä¢	status (ONLINE/OFFLINE/MAINTENANCE)
	‚Ä¢	labels (jsonb)
	‚Ä¢	capabilities (jsonb)
	‚Ä¢	lastHeartbeatAt
	‚Ä¢	pinnedQueues (jsonb)
	‚Ä¢	publicKey / mtlsFingerprint (opcional)

runner_groups
	‚Ä¢	tenantId, name
	‚Ä¢	selector (labels/capabilities)

schedules
	‚Ä¢	tenantId, botVersionId
	‚Ä¢	cron
	‚Ä¢	target (PINNED/GROUP/ANY + selector/runnerId)
	‚Ä¢	timezone
	‚Ä¢	enabled

runs
	‚Ä¢	id
	‚Ä¢	tenantId
	‚Ä¢	botVersionId
	‚Ä¢	status (QUEUED/LEASED/RUNNING/SUCCEEDED/FAILED/CANCELLED)
	‚Ä¢	targetResolved (runnerId)
	‚Ä¢	planHash, policyPackVersion
	‚Ä¢	timestamps

run_events
	‚Ä¢	runId
	‚Ä¢	stepId, eventType, status, durationMs
	‚Ä¢	redactedPayload (jsonb)

‚∏ª

Endpoints ‚Äúcore‚Äù (MVP enterprise)

Runners (Agents)
	‚Ä¢	POST /agents/register
	‚Ä¢	POST /agents/:id/heartbeat
	‚Ä¢	POST /agents/:id/lease  ‚úÖ (pull leasing)
	‚Ä¢	POST /agents/:id/ack (opcional)
	‚Ä¢	POST /agents/:id/reject (opcional)

Bots
	‚Ä¢	POST /bots
	‚Ä¢	POST /bots/:id/versions
	‚Ä¢	GET /bots/:id/versions/:vid/plan ‚úÖ (plan firmado)

Runs
	‚Ä¢	POST /runs (manual trigger)
	‚Ä¢	POST /runs/:id/cancel
	‚Ä¢	GET /runs/:id
	‚Ä¢	POST /runs/:id/events ‚úÖ evidence streaming

Schedules
	‚Ä¢	POST /schedules
	‚Ä¢	PATCH /schedules/:id
	‚Ä¢	POST /schedules/:id/run-now

‚∏ª

Routing: pinned runner (tu necesidad)

Cuando un bot/schedule es PINNED, el job cae en una cola exclusiva:
	‚Ä¢	tenant:{tenantId}:runner:{runnerId}

y solo ese runner hace lease de esa cola.
As√≠ garantizas que ‚Äúese bot corre ah√≠ s√≠ o s√≠‚Äù.

‚∏ª

‚ÄúOrchestrator enciende la VM‚Äù

Eso lo pones como opcional con un m√≥dulo:

infra/:
	‚Ä¢	infra.module.ts
	‚Ä¢	azure-vm.service.ts / aws-ec2.service.ts

Y el scheduler/dispatcher hace:
	‚Ä¢	si runner OFFLINE pero target es PINNED y tiene vmRef ‚Üí startVM() ‚Üí esperar heartbeat ‚Üí lease.

‚∏ª

La pieza m√°s importante del Orchestrator

El pipeline central:

DSL/.skb ‚Üí validate ‚Üí compile plan ‚Üí policy eval ‚Üí sign plan ‚Üí enqueue run ‚Üí lease ‚Üí evidence

Ese es tu ‚Äúsistema nervioso‚Äù.



Runner Agent API + esquema para encender/apagar VMs desde NestJS


S√≠. Aqu√≠ tienes el Runner Agent API (lo que corre ‚Äúal lado‚Äù del runner en la VM del cliente) + el esquema NestJS para encender/apagar VMs desde tu Orchestrator.

La idea ‚Äúenterprise‚Äù es:
	‚Ä¢	Orchestrator (tu SaaS): decide cu√°ndo y qu√© correr, y puede pedir ‚Äúenciende/apaga‚Äù.
	‚Ä¢	Runner Agent (en la red del cliente): es el √∫nico que habla con el hypervisor/cloud del cliente (Azure/AWS/VMware) y expone una API m√≠nima.
Esto es lo m√°s vendible en healthcare: t√∫ NO controlas su infra directamente; ellos s√≠.

‚∏ª

1) Runner Agent API (en cliente)

1.1 Autenticaci√≥n recomendada
	‚Ä¢	mTLS (ideal) entre Orchestrator ‚Üî Runner Agent (outbound desde el cliente si es posible con reverse tunnel).
	‚Ä¢	Alternativa: JWT firmado por tu Orchestrator + allowlist IP.

Adem√°s, cada request de ‚Äúpower‚Äù debe llevar:
	‚Ä¢	commandId
	‚Ä¢	timestamp
	‚Ä¢	signature (firma del Orchestrator)
	‚Ä¢	El agent valida firma + evita replay.

‚∏ª

1.2 Endpoints m√≠nimos

Health & Inventory

GET /v1/health

{ "status": "ok", "agentVersion": "0.4.1", "time": "2026-01-18T..." }

GET /v1/inventory (para matching)

{
  "runnerId": "runner-EPIC-01",
  "os": "windows-2022",
  "capabilities": ["web.open_browser","database.query","robot.execute"],
  "installedSystems": ["EpicClient","CitrixWorkspace"],
  "labels": { "site": "hospitalA", "env": "prod", "hipaa": "true" }
}

VM Power Control (core)

POST /v1/vms/:vmId/start

{
  "commandId": "cmd_123",
  "timestamp": "2026-01-18T03:30:00Z",
  "signature": "base64...",
  "reason": "Run run_abc requires pinned runner runner-EPIC-01"
}

POST /v1/vms/:vmId/stop

{
  "commandId": "cmd_124",
  "timestamp": "2026-01-18T04:10:00Z",
  "signature": "base64...",
  "mode": "deallocate"
}

GET /v1/vms/:vmId/status

{ "vmId": "vm-epic-01", "state": "running", "lastChangeAt": "..." }


Optional (pero √∫til): Wake runner + wait

POST /v1/runners/:runnerId/wake
	‚Ä¢	Internamente: start VM + esperar heartbeat del runner (o servicio)

{
  "commandId": "cmd_200",
  "timestamp": "2026-01-18T...",
  "signature": "base64...",
  "timeoutSec": 300
}

Respuesta:

{ "ok": true, "runnerOnline": true, "observedAt": "..." }

2) Modelo de datos para ‚ÄúVM refs‚Äù

En tu Orchestrator, guarda en runners algo as√≠:

type VmRef =
  | { provider: "azure"; subscriptionId: string; resourceGroup: string; vmName: string }
  | { provider: "aws"; region: string; instanceId: string }
  | { provider: "vmware"; vcenterUrl: string; vmMoRef: string };

type RunnerEntity = {
  runnerId: string;
  tenantId: string;
  status: "ONLINE"|"OFFLINE"|"MAINTENANCE";
  vmRef?: VmRef;
  powerAgentUrl?: string; // URL del Runner Agent dentro del cliente (o tunnel)
};

3) NestJS en el Orchestrator: m√≥dulos y servicios

3.1 M√≥dulo ‚Äúinfra-power‚Äù

src/infra-power/
  infra-power.module.ts
  infra-power.service.ts
  power-agent.client.ts
  dto/
    start-vm.dto.ts
    stop-vm.dto.ts

3.2 Cliente HTTP hacia Runner Agent

// power-agent.client.ts
import { Injectable } from "@nestjs/common";
import axios from "axios";

@Injectable()
export class PowerAgentClient {
  async post(url: string, path: string, body: any, headers: any = {}) {
    return axios.post(`${url}${path}`, body, { headers, timeout: 20_000 }).then(r => r.data);
  }
  async get(url: string, path: string, headers: any = {}) {
    return axios.get(`${url}${path}`, { headers, timeout: 20_000 }).then(r => r.data);
  }
}

3.3 Firmado de comandos (simple)

// signature.service.ts (en common/crypto)
import { Injectable } from "@nestjs/common";
import * as crypto from "crypto";

@Injectable()
export class SignatureService {
  constructor(private readonly secret = process.env.ORCH_SIGNING_SECRET!) {}

  sign(payload: any) {
    const msg = JSON.stringify(payload);
    return crypto.createHmac("sha256", this.secret).update(msg).digest("base64");
  }

  // el Agent validar√° lo mismo del otro lado
}

3.4 Servicio para start/stop con policy anti-replay

// infra-power.service.ts
import { Injectable } from "@nestjs/common";
import { PowerAgentClient } from "./power-agent.client";
import { SignatureService } from "../common/crypto/signature.service";

@Injectable()
export class InfraPowerService {
  constructor(
    private readonly client: PowerAgentClient,
    private readonly sig: SignatureService,
  ) {}

  async startVm(powerAgentUrl: string, vmId: string, reason: string) {
    const payload = {
      commandId: `cmd_${cryptoRandomId()}`,
      timestamp: new Date().toISOString(),
      reason,
    };
    const signature = this.sig.sign(payload);

    return this.client.post(
      powerAgentUrl,
      `/v1/vms/${encodeURIComponent(vmId)}/start`,
      { ...payload, signature },
      { "x-skb-tenant": "..." } // opcional
    );
  }

  async stopVm(powerAgentUrl: string, vmId: string, mode: "shutdown"|"deallocate" = "deallocate") {
    const payload = {
      commandId: `cmd_${cryptoRandomId()}`,
      timestamp: new Date().toISOString(),
      mode,
    };
    const signature = this.sig.sign(payload);

    return this.client.post(
      powerAgentUrl,
      `/v1/vms/${encodeURIComponent(vmId)}/stop`,
      { ...payload, signature }
    );
  }
}

function cryptoRandomId() {
  return Math.random().toString(16).slice(2) + Date.now().toString(16);
}


4) Integraci√≥n con scheduling/dispatch (lo que t√∫ quieres)

Cuando vas a ejecutar un bot PINNED y el runner est√° offline:
	1.	Scheduler crea Run
	2.	Dispatcher intenta rutear al runner pinned
	3.	Si runner.status != ONLINE y tiene vmRef + powerAgentUrl:
	‚Ä¢	InfraPowerService.startVm(...)
	‚Ä¢	esperar heartbeat (hasta X segundos)
	4.	Cuando est√© online ‚Üí lease normal

Pseudoflujo:

if (target.mode === "PINNED") {
  const runner = await runnersService.get(target.runnerId);

  if (!runner.online && runner.powerAgentUrl && runner.vmRef) {
    await infraPower.startVm(runner.powerAgentUrl, vmRefToId(runner.vmRef), `Run ${runId}`);
    await runnersService.waitUntilOnline(runner.runnerId, 300_000);
  }

  enqueueToRunnerQueue(runId, runner.runnerId);
}

5) ¬øY si NO quieres agent y quieres prender VM directo desde tu SaaS?

Se puede, pero en healthcare a veces no te lo dejan. Si el cliente lo permite:
	‚Ä¢	Azure Compute / AWS EC2 keys quedan en su vault y el Orchestrator asume rol
	‚Ä¢	Aun as√≠, yo lo dejo como opci√≥n enterprise, no default.

Default recomendado: Runner Agent local + ellos controlan credenciales de infra.

‚∏ª

6) Lo m√≠nimo que debes guardar en Evidence Pack

Cada ‚Äúpower action‚Äù queda auditado:
	‚Ä¢	qui√©n lo pidi√≥ (tenant/bot/run)
	‚Ä¢	qu√© VM
	‚Ä¢	cu√°ndo
	‚Ä¢	resultado
	‚Ä¢	hash/firma del command

Esto te sube puntos en SOC2/HIPAA.









